{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "022bf988",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests  \n",
    "import re\n",
    "from Bio import SeqIO\n",
    "from Bio import Entrez\n",
    "from Bio import Medline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from Bio import SearchIO\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Seq import Seq\n",
    "import mysql.connector as SQLC\n",
    "import mysql.connector\n",
    "from datetime import date\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from Bio.SeqFeature import CompoundLocation\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5b83b1c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "escolha o que quer pesquisar: gli2\n",
      "escolha o nº de genes que quer obter (máximo 20): 20\n"
     ]
    }
   ],
   "source": [
    "#Extrair ids genebank:\n",
    "\n",
    "data_e_hora_atuais = datetime.now()\n",
    "\n",
    "query= input('escolha o que quer pesquisar: ')\n",
    "\n",
    "\n",
    "try:\n",
    "    def url_get(i):\n",
    "        url_list_id=[]\n",
    "        url = f\"https://www.ncbi.nlm.nih.gov/gene/?term={i}\"\n",
    "        url_list_id.append(url)\n",
    "        return url_list_id\n",
    "    \n",
    "    url_get(query)\n",
    "\n",
    "    content = []\n",
    "    for url in url_get(query):\n",
    "        r = requests.get(url)\n",
    "        content.append(r.content)\n",
    "\n",
    "    for c in content:\n",
    "        soup = BeautifulSoup(c, 'html.parser')\n",
    "        a= soup.get_text()\n",
    "\n",
    "    existe = re.findall(r\"ID:\\s+\\d*(?=\\D)\", a, re.DOTALL)\n",
    "\n",
    "    c= ', '.join(existe)\n",
    "    h= c.replace('ID: ','')\n",
    "    IDS= h.split(', ')\n",
    "\n",
    "    n_gene= IDS[0:1+(int(input('escolha o nº de genes que quer obter (máximo 20): ')))]\n",
    "\n",
    "    n_genes = []\n",
    "    seen = set()\n",
    "    for item in n_gene:\n",
    "        if item not in seen:\n",
    "            seen.add(item)\n",
    "            n_genes.append(item)\n",
    "\n",
    "    numero_genes= len(n_genes)\n",
    "\n",
    "    if n_genes == ['']:\n",
    "        print()\n",
    "        print('0 resultados para a sua pesquisa, pesquise de novo.')\n",
    "\n",
    "except:\n",
    "    ('0 resultados para a sua pesquisa, pesquise de novo.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e05384b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concluido\n"
     ]
    }
   ],
   "source": [
    "#Extrair ids ncbi:\n",
    "Ids=[]\n",
    "database = 'nucleotide'\n",
    "email= 'rodrigoce9@gmail.com'\n",
    "idlist= n_genes\n",
    "handle = Entrez.efetch(db=database, id=idlist, rettype=\"gb\") \n",
    "records = list(SeqIO.parse(handle,\"gb\"))\n",
    "handle.close()\n",
    "for info in records:\n",
    "    Ids.append(info.id)\n",
    "    \n",
    "if Ids == ['']:\n",
    "    print('0 resultados para a sua pesquisa, pesquise de novo.')\n",
    "        \n",
    "#Extrair description NCBI:\n",
    "description=[]\n",
    "database = 'nucleotide'\n",
    "email= 'rodrigoce9@gmail.com'\n",
    "idlist= n_genes\n",
    "handle = Entrez.efetch(db=database, id=idlist, rettype=\"gb\") \n",
    "records = list(SeqIO.parse(handle,\"gb\"))\n",
    "handle.close()\n",
    "for info in records:\n",
    "    description.append(info.description)\n",
    "\n",
    "#organismos\n",
    "Organismos=[]\n",
    "database = 'nucleotide'\n",
    "email= 'rodrigoce9@gmail.com'\n",
    "idlist= n_genes\n",
    "handle = Entrez.efetch(db=database, id=idlist, rettype=\"gb\") \n",
    "records = list(SeqIO.parse(handle,\"gb\"))\n",
    "handle.close()\n",
    "for info in records:\n",
    "    Organismos.append(info.annotations['organism'])\n",
    "    \n",
    "#SEQ\n",
    "seqss=[]\n",
    "database = 'nucleotide'\n",
    "email= 'rodrigoce9@gmail.com'\n",
    "idlist= n_genes\n",
    "handle = Entrez.efetch(db=database, id=idlist, rettype=\"gb\") \n",
    "records = list(SeqIO.parse(handle,\"gb\"))\n",
    "handle.close()\n",
    "for info in records:\n",
    "    seqs= (f'{info.seq[0:10]}...{info.seq[-10:]}')\n",
    "    seqss.append(seqs)\n",
    "\n",
    "#percentagem de nucle:\n",
    "Adenina=[]\n",
    "database = 'nucleotide'\n",
    "email= 'rodrigoce9@gmail.com'\n",
    "idlist= n_genes\n",
    "handle = Entrez.efetch(db=database, id=idlist, rettype=\"gb\") \n",
    "records = list(SeqIO.parse(handle,\"gb\"))\n",
    "handle.close()\n",
    "for info in records:\n",
    "    c=info.seq\n",
    "    count= c.count('A')\n",
    "    perc= int(count/len(c)*100)\n",
    "    Adenina.append(perc)\n",
    "\n",
    "Citosina=[]\n",
    "database = 'nucleotide'\n",
    "email= 'rodrigoce9@gmail.com'\n",
    "idlist= n_genes\n",
    "handle = Entrez.efetch(db=database, id=idlist, rettype=\"gb\") \n",
    "records = list(SeqIO.parse(handle,\"gb\"))\n",
    "handle.close()\n",
    "for info in records:\n",
    "    c=info.seq\n",
    "    count= c.count('C')\n",
    "    perc= int(count/len(c)*100)\n",
    "    Citosina.append(perc)\n",
    "\n",
    "Guanina=[]\n",
    "database = 'nucleotide'\n",
    "email= 'rodrigoce9@gmail.com'\n",
    "idlist= n_genes\n",
    "handle = Entrez.efetch(db=database, id=idlist, rettype=\"gb\") \n",
    "records = list(SeqIO.parse(handle,\"gb\"))\n",
    "handle.close()\n",
    "for info in records:\n",
    "    c=info.seq\n",
    "    count= c.count('G')\n",
    "    perc= int(count/len(c)*100)\n",
    "    Guanina.append(perc)\n",
    "\n",
    "Timina=[]\n",
    "database = 'nucleotide'\n",
    "email= 'rodrigoce9@gmail.com'\n",
    "idlist= n_genes\n",
    "handle = Entrez.efetch(db=database, id=idlist, rettype=\"gb\") \n",
    "records = list(SeqIO.parse(handle,\"gb\"))\n",
    "handle.close()\n",
    "for info in records:\n",
    "    c=info.seq\n",
    "    count= c.count('T')\n",
    "    perc= int(count/len(c)*100)\n",
    "    Timina.append(perc)\n",
    "    \n",
    "#data\n",
    "dates=[]\n",
    "database = 'nucleotide'\n",
    "email= 'rodrigoce9@gmail.com'\n",
    "idlist= n_genes\n",
    "handle = Entrez.efetch(db=database, id=idlist, rettype=\"gb\") \n",
    "records = list(SeqIO.parse(handle,\"gb\"))\n",
    "handle.close()\n",
    "for info in records:\n",
    "    dates.append(info.annotations['date'])\n",
    "\n",
    "#len(SEQ)\n",
    "database = 'nucleotide'\n",
    "email= 'rodrigoce9@gmail.com'\n",
    "idlist= n_genes\n",
    "handle = Entrez.efetch(db=database, id=idlist, rettype=\"gb\") \n",
    "records = list(SeqIO.parse(handle,\"gb\"))\n",
    "handle.close()\n",
    "tam=[]\n",
    "for info in records:\n",
    "    tam.append(len(info.seq))\n",
    "    \n",
    "    # buscar info pubmed\n",
    "try:\n",
    "    def url_get_id(i):\n",
    "        url_list= [ ]\n",
    "        for id in i:\n",
    "            url = \"https://www.ncbi.nlm.nih.gov/nuccore/{}\".format( id )\n",
    "            url_list.append(url)\n",
    "        return url_list\n",
    "    link_genebank= url_get_id(Ids)\n",
    "    #print(link_genebank)\n",
    "\n",
    "    content_id = []\n",
    "    for url in url_get_id(Ids):\n",
    "        r_id = requests.get(url)\n",
    "        content_id.append(r_id.content)\n",
    "\n",
    "    from bs4 import BeautifulSoup\n",
    "    listas=[]\n",
    "\n",
    "    for c in content_id:\n",
    "        soup_id = BeautifulSoup(c, 'html.parser')\n",
    "\n",
    "        lines = soup_id.find_all('meta', {'name':\"ncbi_uidlist\"} )\n",
    "\n",
    "        id = \"\"\n",
    "        url = \"\"\n",
    "        for line in lines:\n",
    "            if 'content' in line.attrs:\n",
    "                id = line.attrs['content']\n",
    "        if id:\n",
    "            url = \"https://www.ncbi.nlm.nih.gov/sviewer/viewer.fcgi?id={}&db=nuccore&report=genbank&conwithfeat=on&hide-cdd=on&retmode=text&maxdownloadsize=5000000\".format(id)\n",
    "        r2 = requests.get(url)\n",
    "        r4= r2.content.decode('utf-8')\n",
    "        listas.append(r4)\n",
    "\n",
    "    cc= ', '.join(listas)\n",
    "    er= cc.replace('//','')\n",
    "    final= er.split(', ')\n",
    "\n",
    "    #criar dicionário de ids ncbi e ids pubmed\n",
    "    output_dict = {}\n",
    "    for x in final:\n",
    "        version = re.search(r'VERSION\\s+(.*?)\\s', x)\n",
    "        pubmed = re.search(r'PUBMED\\s+(.*?)\\s', x)\n",
    "        if version:\n",
    "            versionf=version.group(1)\n",
    "            output_dict.setdefault(version.group(1), [])\n",
    "        if pubmed:\n",
    "            output_dict[versionf].append(pubmed.group(1))\n",
    "except:\n",
    "    print()\n",
    "    print(\"0 resultados na Pubmed em realção à sua query\")\n",
    "    \n",
    "#Criar Listas só com ids ncbi e ids pubmed\n",
    "id_ncbii = []\n",
    "ID_PUB = []\n",
    "for key, vals in output_dict.items():\n",
    "    if vals:\n",
    "        for val in vals:\n",
    "            id_ncbii.append(key)\n",
    "            ID_PUB.append(val)\n",
    "    else:\n",
    "        id_ncbii.append(key)\n",
    "        ID_PUB.append(\"N/A\")\n",
    "\n",
    "new_list_ = []\n",
    "seen = set()\n",
    "for item in ID_PUB:\n",
    "    if item not in seen:\n",
    "        seen.add(item)\n",
    "        new_list_.append(item)\n",
    "\n",
    "print(\"Concluido\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "949a591d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concluido\n"
     ]
    }
   ],
   "source": [
    "#Extrair informação de artigos\n",
    "try:\n",
    "    titles=[]\n",
    "    authors=[]\n",
    "    source=[]\n",
    "    affiliation=[]\n",
    "    database = 'PubMed'\n",
    "    email= 'rodrigoce9@gmail.com'\n",
    "    idlist= new_list_\n",
    "    counter = 0\n",
    "    for i in idlist:\n",
    "        if i!= \"N/A\":\n",
    "            handle = Entrez.efetch(db=database, id=i, rettype=\"medline\", retmode=\"text\") \n",
    "            records = Medline.parse(handle)\n",
    "            for info in records:\n",
    "                titles.append(info.get(\"TI\", [\"N/A\"]))\n",
    "                authors_string = info.get(\"AU\", [\"N/A\"])\n",
    "                if len(authors_string) > 5:\n",
    "                    authors_h = authors_string[0:5]\n",
    "                    authors.append(authors_h)\n",
    "                else:\n",
    "                    authors.append(authors_string) \n",
    "                source.append(info.get(\"SO\", [\"N/A\"]))\n",
    "                affiliation_string= info.get(\"AD\", [\"N/A\"])\n",
    "                if len(affiliation_string) > 5:\n",
    "                    affiliation_h = affiliation_string[0:5]\n",
    "                    affiliation.append(affiliation_h)\n",
    "                else:\n",
    "                    affiliation.append(affiliation_string)\n",
    "                counter += 1\n",
    "        else:\n",
    "            titles.append([\"N/A\"])\n",
    "            authors.append([\"N/A\"])\n",
    "            source.append([\"N/A\"])\n",
    "            affiliation.append([\"N/A\"])\n",
    "            counter += 1\n",
    "except:\n",
    "    print('artigos não encontrados por um possivel bug de id')\n",
    "    \n",
    "#agrupar titles\n",
    "titles = [ [title] for title in titles]\n",
    "\n",
    "# agrupar dois\n",
    "doi_list = []\n",
    "for x in source:\n",
    "    match = re.search(\"doi: (.*)\", str(x))\n",
    "    if match:\n",
    "        doi_list.append(match.group(1))\n",
    "    else:\n",
    "        doi_list.append(\"N/A\")\n",
    "        \n",
    "#agrupar authors\n",
    "id_authors_dict = {i: authors[counter] if i != \"N/A\" else [\"N/A\"] for counter, i in enumerate(idlist)}        \n",
    "        \n",
    "pubmed_list = []\n",
    "authors_list = []\n",
    "for key, vals in id_authors_dict.items():\n",
    "    if vals:\n",
    "        for val in vals:\n",
    "            pubmed_list.append(key)\n",
    "            authors_list.append(val)\n",
    "\n",
    "new_list_authors= []\n",
    "seen = set()\n",
    "for item in authors_list:\n",
    "    if item not in seen:\n",
    "        seen.add(item)\n",
    "        new_list_authors.append(item)\n",
    "\n",
    "#agrupar affi\n",
    "single_affiliation_list = []\n",
    "for i in affiliation:\n",
    "    single_affiliation_list.extend(i)\n",
    "    \n",
    "\n",
    "id_affiliation_dict = {i: [single_affiliation_list[counter]] if i != \"N/A\" else [\"N/A\"] for counter, i in enumerate(idlist)}\n",
    "\n",
    "pubmed_affi_list = []\n",
    "affi_list = []\n",
    "for key, vals in id_affiliation_dict.items():\n",
    "    if vals:\n",
    "        for val in vals:\n",
    "            pubmed_affi_list.append(key)\n",
    "            affi_list.append(val)\n",
    "    else:\n",
    "        pubmed_affi_list.append(key)\n",
    "        affi_list.append([\"N/A\"])\n",
    "\n",
    "new_list_affi= []\n",
    "seen = set()\n",
    "for item in single_affiliation_list :\n",
    "    if item not in seen:\n",
    "        seen.add(item)\n",
    "        new_list_affi.append(item)\n",
    "\n",
    "def url_get_id_p(string):\n",
    "    url_list_p=[ ]\n",
    "    url_id_p= \"https://www.uniprot.org/uniprotkb/{}/entry\".format(str(string))\n",
    "    url_list_p.append(url_id_p)\n",
    "    return ''.join(url_list_p)\n",
    "\n",
    "# protein_id - PROT_ID \n",
    "list_pro=[]\n",
    "database = 'nucleotide'\n",
    "email= 'rodrigoce9@gmail.com'\n",
    "idlist= n_genes\n",
    "handle = Entrez.efetch(db=database, id=idlist, rettype=\"gb\") \n",
    "records = list(SeqIO.parse(handle,\"gb\"))\n",
    "handle.close()\n",
    "for info in records:\n",
    "    for i in info.features:\n",
    "        if i.type == \"CDS\":\n",
    "            pro= str(i.qualifiers[\"protein_id\"])\n",
    "            list_pro.append(pro)\n",
    "div= ', '.join(list_pro)\n",
    "h= div.replace(\"['\",'')\n",
    "hh= h.replace(\"']\",'')\n",
    "ID_PROT= hh.split(', ')\n",
    "\n",
    "#result_dic = {Ids, ID_PROT} - \n",
    "result_dict = {}\n",
    "database = 'nucleotide'\n",
    "email= 'rodrigoce9@gmail.com'\n",
    "idlist=Ids\n",
    "for ids in idlist:\n",
    "    list_pro=[]\n",
    "#     print( ids)\n",
    "    handle = Entrez.efetch(db=database, id=ids, rettype=\"gb\") \n",
    "    records = list(SeqIO.parse(handle,\"gb\"))\n",
    "    handle.close()\n",
    "    for info in records:\n",
    "        list_pro.append(info.id)\n",
    "        for i in info.features:\n",
    "            if i.type == \"CDS\":\n",
    "                pro= str(i.qualifiers[\"protein_id\"])\n",
    "                list_pro.append(pro)\n",
    "        if len(list_pro)==1: #if no protein_id was found\n",
    "            result_dict[info.id] = \"N/A_CDS\"\n",
    "        else:\n",
    "            list_pro = [x.replace(\"['\",'').replace(\"']\",'') for x in list_pro]\n",
    "            result_dict[info.id] = ', '.join(list_pro[1:])\n",
    "#key: id_genebank; values: ID_PROT\n",
    "\n",
    "def dict_to_list(d, delimiter=','): #transforms dictionary to list\n",
    "    new_list = []\n",
    "    for k, v in d.items():\n",
    "        if isinstance(v, str):\n",
    "            values = v.split(delimiter)\n",
    "            for val in values:\n",
    "                new_list.append([k, val.strip()])\n",
    "        else:\n",
    "            new_list.append([k, v])\n",
    "    return new_list\n",
    "dict_list=dict_to_list(result_dict)\n",
    "\n",
    "\n",
    "from collections import OrderedDict\n",
    "def get_CDS_info(result_dict): #gets info for CDS [ID_CDS, location, Translation]\n",
    "    database = 'nucleotide'\n",
    "    email= 'rodrigoce9@gmail.com'\n",
    "    Entrez.email = email\n",
    "    cds_location_list = []\n",
    "    several_location = []\n",
    "    record_types={}\n",
    "    processed_i = set()\n",
    "    for i, value in result_dict.items():\n",
    "        if i in processed_i:\n",
    "            continue\n",
    "        if value == 'N/A_CDS':\n",
    "            cds_location = ['N/A_CDS', 'N/A', 'N/A']\n",
    "            cds_location_list.append(cds_location)\n",
    "        else:\n",
    "            handle = Entrez.efetch(db=database, id=i, rettype=\"gb\") \n",
    "            records = list(SeqIO.parse(handle,\"gb\"))\n",
    "            handle.close()\n",
    "            for info in records:\n",
    "                for i in info.features:\n",
    "                    if i.type == \"CDS\":\n",
    "                        cds_location = []\n",
    "                        i_d = str(i.qualifiers[\"protein_id\"])\n",
    "                        translation =  str(i.qualifiers[\"translation\"])\n",
    "                        cds_location.append(i_d)\n",
    "                        if isinstance(i.location, CompoundLocation):\n",
    "                            for sub_location in i.location.parts:\n",
    "                                several_location.append(\"[{} : {}]\".format(sub_location.start, sub_location.end))\n",
    "                            cds_location.append(several_location)\n",
    "                            cds_location.append(translation)\n",
    "                        else:\n",
    "                            cds_location.append(\"[{} : {}]\".format(i.location.start, i.location.end))\n",
    "                            cds_location.append(translation)\n",
    "                        cds_location_list.append(cds_location)      \n",
    "                processed_i.add(i)\n",
    "            handle.close()\n",
    "    return cds_location_list   \n",
    "\n",
    "WEBSITE_API = \"https://rest.uniprot.org\"\n",
    "fields = [\"accession\",\"organism_name\",\"protein_name\",\"cc_subcellular_location\",\"cc_function\", \"sequence\"]\n",
    "def get_url(url, **kwargs):\n",
    "    response = requests.get(url, **kwargs);\n",
    "    if not response.ok:\n",
    "        print(response.text)\n",
    "        response.raise_for_status()\n",
    "        sys.exit()\n",
    "    return response\n",
    "\n",
    "#get list of [ID_Uniprot, Subcellular location, Function, Sequence, Sequence length]\n",
    "def get_field_for_id(ID_PROT, field): \n",
    "    response = get_url(\"{}/uniprotkb/search?query={}&fields={}&size=1&format=tsv\".format(WEBSITE_API,ID_PROT,field))\n",
    "    return str(response.content)\n",
    "\n",
    "try:\n",
    "    def get_list_uniprot(ID_PROT, result_dict):\n",
    "        results = []\n",
    "        result = []\n",
    "        tmp= []\n",
    "        easy=dict_to_list(result_dict)\n",
    "        for first_index, first_value in easy:\n",
    "            tmp= []\n",
    "            if first_value != 'N/A_CDS':\n",
    "                for field in fields:\n",
    "                    result = get_field_for_id(first_value, field)\n",
    "                    tmp.append(result)\n",
    "            else:\n",
    "                result = ['N/A_Uniprot']\n",
    "                tmp.append(result)\n",
    "            results.append(tmp)   \n",
    "        uniprot_final_list=[]\n",
    "        for index, values in enumerate(results):\n",
    "            uniprot_list=[]\n",
    "            n_a = re.search(r'(N/A_Uniprot)', str(values), re.DOTALL)\n",
    "            if len (values)==1:\n",
    "                if n_a:\n",
    "                    uniprot_list.append(n_a.group(1))\n",
    "                    tmp_list='N/A','N/A','N/A','N/A'\n",
    "                    uniprot_list.extend(tmp_list)\n",
    "            else:\n",
    "                for i in values:\n",
    "                    entry = re.search(r'b\\'Entry\\\\n(.+?(?=\\\\n\\'))', str(i), re.DOTALL)\n",
    "                    function = re.match( r'b\\'Function \\[CC\\]\\\\n.{9} (.+?(?=\\\\n\\'))', str(i), re.DOTALL )\n",
    "                    location_exist = re.search( r'b\\'Subcellular location \\[CC\\]\\\\nSUBCELLULAR LOCATION: (.+?(?=\\\\n\\'))', str(i), re.DOTALL )\n",
    "                    location_notexist = re.search( r'b\\'Subcellular location \\[CC\\]\\\\n\\\\n\\'',str(i), re.DOTALL )   \n",
    "                    sequence = re.search(r'b\\'Sequence\\\\n(.+?(?=\\\\n\\'))', str(i), re.DOTALL)\n",
    "                    if entry:\n",
    "                        ent=entry.group(1)\n",
    "                        uniprot_list.append(entry.group(1))            \n",
    "                    if function:\n",
    "                        uniprot_list.append(function.group(1))\n",
    "                    if location_exist:\n",
    "                        uniprot_list.append(location_exist.group(1))\n",
    "                    if location_notexist:\n",
    "                        uniprot_list.append(\"N/A\")\n",
    "                    if sequence:\n",
    "                        uniprot_list.append(sequence.group(1))\n",
    "                        uniprot_list.append(len(sequence.group(1)))\n",
    "                        uniprot_list.append(url_get_id_p(ent))\n",
    "\n",
    "            if len(uniprot_list) < 6: #sometimes, there is no function associated\n",
    "                uniprot_list.insert(2, 'N/A')\n",
    "            uniprot_final_list.append(uniprot_list)\n",
    "\n",
    "        return uniprot_final_list\n",
    "    get_Uniprot=get_list_uniprot(ID_PROT,result_dict)    \n",
    "except:\n",
    "    print(\"A informação foi apagada \")\n",
    "    \n",
    "#[idgenebank, protein_id, id do uniprot] \n",
    "#joins to final list [idgenebank, ID_PRO, ID_Uniprot]\n",
    "def join_ids_CDS(lista, uniprotID): \n",
    "    join_list_all = []\n",
    "    for key, value in lista:\n",
    "        join_list = []\n",
    "        join_list.append(key)\n",
    "        join_list.append(value)\n",
    "        join_list_all.append(join_list) \n",
    "    for index, values in enumerate(uniprotID):\n",
    "        join_list_all[index].append(uniprotID[index][0])\n",
    "    return join_list_all\n",
    "join_ids=join_ids_CDS(dict_list,get_list_uniprot(ID_PROT, result_dict))\n",
    "\n",
    "\n",
    "def join_lists(list1, list2): #joins to final list [idgenebank, ID_PRO, ID_Uniprot,location, Translation]\n",
    "    final_result =[]\n",
    "    list_tmp=[]\n",
    "    tmp=''\n",
    "    for item, value in enumerate(list1):\n",
    "        result = []\n",
    "        string_item = str(list2[item][0])\n",
    "        string_item = string_item.replace(\"[\",\"\").replace(\"]\",\"\").replace(\"'\",\"\")\n",
    "        if list1[item][1] == string_item:\n",
    "            result.append(list1[item] + list2[item][1:])\n",
    "            tmp=list1[item][0]\n",
    "        elif list1[item][0] == tmp:\n",
    "            list_tmp = []\n",
    "            list_tmp.append(tmp)\n",
    "            list_tmp.append(list1[item][1])\n",
    "            list_tmp.append(list1[item][2])\n",
    "            result.append(list_tmp + list2[item][1:])\n",
    "        else:\n",
    "            result.append(list1[item])\n",
    "        final_result.extend(result)\n",
    "    return final_result\n",
    "join_CDS=join_lists(join_ids, get_CDS_info(result_dict))\n",
    "\n",
    "def count_(genes):\n",
    "    return len(genes)\n",
    "count_(Ids)\n",
    "count_(ID_PROT)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Concluido\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "da3ff3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete de tudo \n",
    "\n",
    "DataBase = SQLC.connect(\n",
    "    host =\"geo.di.uminho.pt\",\n",
    "    user =\"bioinformatica\",\n",
    "    password =\"20221207\",\n",
    "    database =\"AP_db_KRG\"\n",
    ")\n",
    "DataBase.autocommit = True # allows the change be done\n",
    "\n",
    "Cursor = DataBase.cursor()\n",
    "try:\n",
    "        \n",
    "        a= \"delete from PubMed_Affiliation\"\n",
    "        Z= \"delete from PubMed_Authors\"\n",
    "        b= \"delete from Affiliation\"\n",
    "        c= \"delete from Authors\"\n",
    "        d= \"delete from gene_PubMed\"\n",
    "        e= \"delete from PubMed\"\n",
    "        f= \"delete from CDS\"\n",
    "        g= \"delete from Uniprot\"\n",
    "        h= \"delete from Gene\"\n",
    "        #i= \"delete from History\"     \n",
    "        \n",
    "        Cursor.execute(a)\n",
    "        Cursor.execute(Z)\n",
    "        Cursor.execute(b)\n",
    "        Cursor.execute(c)\n",
    "        Cursor.execute(d)\n",
    "        Cursor.execute(e)\n",
    "        Cursor.execute(f)\n",
    "        Cursor.execute(g)\n",
    "        Cursor.execute(h)\n",
    "        #Cursor.execute(i)\n",
    "        \n",
    "except mysql.connector.Error as e:\n",
    "    print(\"Erro na escrita na base de dados: {}\".format(e) )    \n",
    "finally:\n",
    "    DataBase.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "40bbca2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concluido\n"
     ]
    }
   ],
   "source": [
    "#Povoação \"History\"\n",
    "\n",
    "DataBase = SQLC.connect(\n",
    "    host =\"geo.di.uminho.pt\",\n",
    "    user =\"bioinformatica\",\n",
    "    password =\"20221207\",\n",
    "    database =\"AP_db_KRG\"\n",
    ")\n",
    "DataBase.autocommit = True # allows the change be done\n",
    "\n",
    "Cursor = DataBase.cursor()\n",
    "try:\n",
    "    sql1= \"INSERT INTO History (search, Genes_number_input, Day, Genes_number_NCBI, Protein_number  )   VALUES (%s, %s, %s, %s, %s)\"\n",
    "    val1=(query, numero_genes, data_e_hora_atuais, count_(Ids), count_(ID_PROT) )\n",
    "    Cursor.execute(sql1,val1)\n",
    "    \n",
    "except mysql.connector.Error as e:\n",
    "    print(\"Erro na escrita na base de dados: {}\".format(e) ) \n",
    "    \n",
    "search_id=[]\n",
    "try:\n",
    "    sql2= \"Select ID_search FROM History\"\n",
    "    Cursor.execute(sql2)\n",
    "    for row in Cursor:\n",
    "        search_id.append(str(row)) \n",
    "        \n",
    "except mysql.connector.Error as e:\n",
    "    print(\"Erro na escrita na base de dados: {}\".format(e) )    \n",
    "    \n",
    "div= ', '.join(search_id)\n",
    "h= div.replace(\"(\",'')\n",
    "hh= h.replace(\",)\",'')\n",
    "SEARCH_ID= hh.split(', ')\n",
    "Hist= SEARCH_ID[-1]\n",
    "\n",
    "#Povoação \"Gene\"-\n",
    "\n",
    "des = (description)\n",
    "\n",
    "try:\n",
    "    for index, value in enumerate(Ids):\n",
    "       \n",
    "        sql3= \"INSERT INTO Gene (ID_genebank, Description, Organism, sequence, Date_publish, length, Adenina, Citosina, Guanina, Timina, Link, ID_search) VALUES ( %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\"\n",
    "        val3=(value, des[index], Organismos[index], seqss[index], dates[index], tam[index], Adenina[index], Citosina[index], Guanina[index], Timina[index], link_genebank[index], Hist)\n",
    "\n",
    "        Cursor.execute(sql3,val3)\n",
    "\n",
    "except mysql.connector.Error as e:\n",
    "    print(\"Erro na escrita na base de dados: {}\".format(e) )    \n",
    "    \n",
    "#Povoar \"PubMed\"\n",
    "\n",
    "try:\n",
    "    for index, value in enumerate(new_list_):\n",
    "        sql4= \"INSERT INTO PubMed (ID_PumMed, title, Doi_number) VALUES (%s, %s, %s)\"\n",
    "        val4=(str(new_list_[index]), str(titles[index]), str(doi_list[index]) )\n",
    "        Cursor.execute(sql4,val4)\n",
    "\n",
    "except mysql.connector.Error as e:\n",
    "    print(\"Erro na escrita na base de dados: {}\".format(e) )    \n",
    "\n",
    "    \n",
    "#retirar os valores AI de pubmed\n",
    "ID_AI=[]\n",
    "\n",
    "try:\n",
    "    sql5= \"Select ID_AI_PubMed FROM PubMed\"\n",
    "    Cursor.execute(sql5)\n",
    "    for row in Cursor:\n",
    "        ID_AI.append(str(row))       \n",
    "except mysql.connector.Error as e:\n",
    "    print(\"Erro na escrita na base de dados: {}\".format(e) )    \n",
    "      \n",
    "div_= ', '.join(ID_AI)\n",
    "h_= div_.replace(\"(\",'')\n",
    "hh_= h_.replace(\",)\",'')\n",
    "SEARCH_ID_= hh_.split(', ')\n",
    "#print(SEARCH_ID_)\n",
    "\n",
    "#Povação \"Gene-Pubmed\"\n",
    "number_map = {}\n",
    "next_number = int(SEARCH_ID_[0])\n",
    "relation = []\n",
    "for number in ID_PUB:\n",
    "    if number not in number_map:\n",
    "        number_map[number] = next_number\n",
    "        next_number += 1\n",
    "    relation.append(number_map[number])\n",
    "    \n",
    "try:\n",
    "    for index, value in enumerate(id_ncbii):\n",
    "        \n",
    "        sql6= \"INSERT INTO gene_PubMed (ID_genebank, ID_AI_PubMed) VALUES (%s, %s)\"\n",
    "        val6=(id_ncbii[index], relation[index])\n",
    "    \n",
    "        Cursor.execute(sql6,val6)\n",
    "\n",
    "except mysql.connector.Error as e:\n",
    "    print(\"Erro na escrita na base de dados: {}\".format(e) )    \n",
    "    \n",
    "#Povação \"authors\"\n",
    "try:\n",
    "    for index, value in enumerate(new_list_authors):\n",
    "        \n",
    "        sql7= \"INSERT INTO Authors (Name) VALUES (%s)\"\n",
    "        val7=(new_list_authors[index],)\n",
    "    \n",
    "        Cursor.execute(sql7,val7)\n",
    "\n",
    "except mysql.connector.Error as e:\n",
    "    print(\"Erro na escrita na base de dados: {}\".format(e) )    \n",
    "\n",
    "#retirar os valores AI de authors\n",
    "ID_AI_Authors=[]\n",
    "\n",
    "try:\n",
    "    sql8= \"Select ID_Authors FROM Authors\"\n",
    "    Cursor.execute(sql8)\n",
    "    for row in Cursor:\n",
    "        ID_AI_Authors.append(str(row))       \n",
    "except mysql.connector.Error as e:\n",
    "    print(\"Erro na escrita na base de dados: {}\".format(e) )    \n",
    "    \n",
    "div_Authors= ', '.join(ID_AI_Authors)\n",
    "h_Authors= div_Authors.replace(\"(\",'')\n",
    "hh_Authors= h_Authors.replace(\",)\",'')\n",
    "SEARCH_ID_Authors= hh_Authors.split(', ')\n",
    "#print(SEARCH_ID_Authors)\n",
    "\n",
    "#Povação \"Pubmed-Authors\"\n",
    "number_map_ = {}\n",
    "next_number = int(SEARCH_ID_Authors[0])\n",
    "output_authors = []\n",
    "for number in authors_list:\n",
    "    if number not in number_map_:\n",
    "        number_map_[number] = next_number\n",
    "        next_number += 1\n",
    "    output_authors.append(number_map_[number])\n",
    "\n",
    "number_map_pub = {}\n",
    "next_number = int(SEARCH_ID_[0])\n",
    "output_pub = []\n",
    "for number in pubmed_list:\n",
    "    if number not in number_map_pub:\n",
    "        number_map_pub[number] = next_number\n",
    "        next_number += 1\n",
    "    output_pub.append(number_map_pub[number])\n",
    "\n",
    "try:\n",
    "    for index, value in enumerate(output_pub):\n",
    "        \n",
    "        sql9= \"INSERT INTO PubMed_Authors (ID_AI_PubMed, ID_Authors) VALUES (%s, %s)\"\n",
    "        val9=(str(output_pub[index]),str(output_authors[index]))\n",
    "    \n",
    "        Cursor.execute(sql9,val9)\n",
    "\n",
    "except mysql.connector.Error as e:\n",
    "    print(\"Erro na escrita na base de dados: {}\".format(e) )    \n",
    "    \n",
    "#Povação \"affi\"\n",
    "\n",
    "try:\n",
    "    for index, value in enumerate(new_list_affi):\n",
    "        \n",
    "        sql10= \"INSERT INTO Affiliation (Info) VALUES (%s)\"\n",
    "        val10=(new_list_affi[index],)\n",
    "    \n",
    "        Cursor.execute(sql10,val10)\n",
    "\n",
    "except mysql.connector.Error as e:\n",
    "    print(\"Erro na escrita na base de dados: {}\".format(e) )    \n",
    "    \n",
    "#retirar os valores AI de affi\n",
    "ID_AI_Affiliation=[]\n",
    "\n",
    "try:\n",
    "    sql11= \"Select ID_Affiliation FROM Affiliation\"\n",
    "    Cursor.execute(sql11)\n",
    "    for row in Cursor:\n",
    "        ID_AI_Affiliation.append(str(row))       \n",
    "except mysql.connector.Error as e:\n",
    "    print(\"Erro na escrita na base de dados: {}\".format(e) )    \n",
    "    \n",
    "div_Affiliation= ', '.join(ID_AI_Affiliation)\n",
    "h_Affiliation= div_Affiliation.replace(\"(\",'')\n",
    "hh_Affiliation= h_Affiliation.replace(\",)\",'')\n",
    "SEARCH_ID_Affiliation= hh_Affiliation.split(', ')\n",
    "#print(SEARCH_ID_Affiliation)\n",
    "\n",
    "#Povação \"Pubmed-Affiliation\"\n",
    "number_map_affi_pub = {}\n",
    "next_number = int(SEARCH_ID_[0])\n",
    "output_pub_affi = []\n",
    "for number in pubmed_affi_list:\n",
    "    if number not in number_map_affi_pub:\n",
    "        number_map_affi_pub[number] = next_number\n",
    "        next_number += 1\n",
    "    output_pub_affi.append(number_map_affi_pub[number])\n",
    "    \n",
    "number_map_affi = {}\n",
    "next_number = int(SEARCH_ID_Affiliation[0])\n",
    "output_affi = []\n",
    "for number in affi_list:\n",
    "    if number not in number_map_affi:\n",
    "        number_map_affi[number] = next_number\n",
    "        next_number += 1\n",
    "    output_affi.append(number_map_affi[number])\n",
    "\n",
    "try:\n",
    "    for index, value in enumerate(output_pub_affi):\n",
    "        \n",
    "        sql12= \"INSERT INTO PubMed_Affiliation (ID_AI_PubMed, ID_Affiliation) VALUES (%s, %s)\"\n",
    "        val12=(str(output_pub_affi[index]),str(output_affi[index]))\n",
    "    \n",
    "        Cursor.execute(sql12,val12)\n",
    "\n",
    "except mysql.connector.Error as e:\n",
    "    print(\"Erro na escrita na base de dados: {}\".format(e) )    \n",
    "\n",
    "#Povoação \"Uniprot\" \n",
    "# print(get_Uniprot) #(ID_Uniprot, Subcelular location, Function, Protein seq, length_aa) \n",
    "\n",
    "a=[\"N/A_Uniprot\"]\n",
    "\n",
    "try:\n",
    "    sec1 = 'INSERT INTO Uniprot (ID_Uniprot, Subcelular_Location, Function, Protein_sequence, length_aa, Link_Uniprot) VALUES (%s, %s, %s, %s, %s, %s)'\n",
    "    Cursor.execute(sec1, (a[0],a[0],a[0],a[0],a[0],a[0]))\n",
    "    for index, value in enumerate(get_Uniprot):\n",
    "        if str(value[0]) == 'N/A_Uniprot':\n",
    "            continue\n",
    "        else:\n",
    "            sql13= \"INSERT INTO Uniprot (ID_Uniprot, Subcelular_Location, Function, Protein_sequence, length_aa, Link_Uniprot) VALUES (%s, %s, %s, %s, %s, %s)\"\n",
    "            val13=(str(value[0]), str(value[1]), str(value[2]), str(value[3]), str(value[4]), str(value[5]))\n",
    "            Cursor.execute(sql13,val13)\n",
    "\n",
    "except mysql.connector.Error as e:\n",
    "    print(\"Erro na escrita na base de dados: {}\".format(e) )    \n",
    "\n",
    "#Povoação \"CDS\"\n",
    "try:\n",
    "    for item in join_CDS:\n",
    "        sql14= \"INSERT INTO CDS (ID_CDS, Translation, Location, ID_genebank, ID_Uniprot) VALUES (%s, %s, %s, %s, %s)\"\n",
    "        val14=(str(item[1]),str(item[4]),str(item[3]),str(item[0]),str(item[2]))\n",
    "        Cursor.execute(sql14,val14)\n",
    "except mysql.connector.Error as e:\n",
    "    print(\"Erro na escrita na base de dados: {}\".format(e) )    \n",
    "finally:\n",
    "    DataBase.close()\n",
    "\n",
    "print(\"Concluido\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a47a948f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import pandas as pd \n",
    "\n",
    "# DataBase = SQLC.connect(\n",
    "#     host =\"geo.di.uminho.pt\",\n",
    "#     user =\"bioinformatica\",\n",
    "#     password =\"20221207\",\n",
    "#     database =\"AP_db_KRG\"\n",
    "# )\n",
    "# tabela1 = pd.read_sql(\"Select * FROM History\", DataBase)\n",
    "# print(tabela1)\n",
    "# tabela2 = pd.read_sql(\"Select * FROM Gene\", DataBase)\n",
    "# print(tabela2)\n",
    "# tabela3 = pd.read_sql(\"Select * FROM gene_PubMed\", DataBase)\n",
    "# print(tabela3)\n",
    "# tabela4 = pd.read_sql(\"Select * FROM PubMed\", DataBase)\n",
    "# print(tabela4)\n",
    "# tabela5 = pd.read_sql(\"Select * FROM PubMed_Authors\", DataBase)\n",
    "# print(tabela5)\n",
    "# tabela6 = pd.read_sql(\"Select * FROM Authors\", DataBase)\n",
    "# print(tabela6)\n",
    "# tabela7 = pd.read_sql(\"Select * FROM PubMed\", DataBase)\n",
    "# print(tabela7)\n",
    "# tabela8 = pd.read_sql(\"Select * FROM PubMed_Affiliation\", DataBase)\n",
    "# print(tabela8)\n",
    "# tabela9 = pd.read_sql(\"Select * FROM Affiliation\", DataBase)\n",
    "# print(tabela9)\n",
    "# tabela10 = pd.read_sql(\"Select * FROM CDS\", DataBase)#print(tabela10)\n",
    "# print(tabela10)\n",
    "# tabela11 = pd.read_sql(\"Select * FROM Uniprot\", DataBase)\n",
    "# print(tabela11)\n",
    "# DataBase.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8928e80",
   "metadata": {},
   "source": [
    "# Algoritmos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "329701bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Escolha o tamanho máximo das seq: 50\n",
      "[\"('AAADK0043071.1', 21)\", \"('AAADS0003348.1', 20)\", \"('AAADW0009410.1', 21)\", \"('AAADX0043451.1', 21)\", \"('ABAAM0346030.1', 20)\"]\n"
     ]
    }
   ],
   "source": [
    "DataBase = SQLC.connect(\n",
    "    host =\"geo.di.uminho.pt\",\n",
    "    user =\"bioinformatica\",\n",
    "    password =\"20221207\",\n",
    "    database =\"AP_db_KRG\"\n",
    ")\n",
    "DataBase.autocommit = True \n",
    "Cursor = DataBase.cursor()\n",
    "\n",
    "num= input(\"Escolha o tamanho máximo das seq: \")\n",
    "Seq_and_length=[]\n",
    "just_seq=[]\n",
    "try:\n",
    "    sql_Seq_length= f\"select Gene.ID_genebank, Gene.length from Gene where Gene.length <{num}\"\n",
    "    Cursor.execute(sql_Seq_length)\n",
    "    for row in Cursor:\n",
    "        Seq_and_length.append(str(row)) \n",
    "    \n",
    "    sql_Seq= f\"select Gene.ID_genebank from Gene where Gene.length <{num}\"\n",
    "    Cursor.execute(sql_Seq)\n",
    "    for row in Cursor:\n",
    "        just_seq.append(str(row))\n",
    "        \n",
    "except mysql.connector.Error as e:\n",
    "    print(\"Erro na escrita na base de dados: {}\".format(e) )    \n",
    "    \n",
    "print (Seq_and_length)\n",
    "\n",
    "if just_seq == []:\n",
    "        print()\n",
    "        print('nenhuma seq inferior a esse tamanho, pesquise de novo.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31323354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "escolha a primeira seq com que quer trabalhar: 0\n",
      "escolha a segunda seq com que quer trabalhar: 1\n",
      "['AAADK0043071.1', 'AAADS0003348.1']\n"
     ]
    }
   ],
   "source": [
    "list_seq=[]\n",
    "\n",
    "choose= input('escolha a primeira seq com que quer trabalhar: ')\n",
    "inter= int(choose)\n",
    "extr= ', '.join(just_seq)\n",
    "h= extr.replace(\"(\",'')\n",
    "hh= h.replace(\",)\",'')\n",
    "ID_al= hh.split(', ')\n",
    "select= ID_al[inter]\n",
    "list_seq.append(select)\n",
    "\n",
    "choose2= input('escolha a segunda seq com que quer trabalhar: ')\n",
    "inter2= int(choose2)\n",
    "extr2= ', '.join(just_seq)\n",
    "h2= extr2.replace(\"(\",'')\n",
    "hh2= h2.replace(\",)\",'')\n",
    "ID_al2= hh2.split(', ')\n",
    "select2= ID_al2[inter2]\n",
    "list_seq.append(select2)\n",
    "\n",
    "limpar_aspas= ', '.join(list_seq)\n",
    "retirar= limpar_aspas.replace(\"'\",\"\")\n",
    "otput_final= retirar.split(', ')\n",
    "print(otput_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "17ab2b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAGTGGAGATGGCGGAGCTGT\n",
      "\n",
      "CAACACGGGAAACCTCACCC\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# #SEQ_algoritmos\n",
    "# seq_for_al=[]\n",
    "# database = 'nucleotide'\n",
    "# email= 'rodrigoce9@gmail.com'\n",
    "# idlist= otput_final\n",
    "# for x in idlist:\n",
    "#     handle = Entrez.efetch(db=database, id=x, rettype=\"gb\") \n",
    "#     records = SeqIO.read(handle,\"gb\")\n",
    "#     handle.close()\n",
    "#     print(records.seq)\n",
    "#     print()\n",
    "#     seq_for_al.append(records.seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e5f405e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utilizador/opt/anaconda3/lib/python3.9/site-packages/Bio/Entrez/__init__.py:658: UserWarning: \n",
      "Email address is not specified.\n",
      "\n",
      "To make use of NCBI's E-utilities, NCBI requires you to specify your\n",
      "email address with each request.  As an example, if your email address\n",
      "is A.N.Other@example.com, you can specify it as follows:\n",
      "   from Bio import Entrez\n",
      "   Entrez.email = 'A.N.Other@example.com'\n",
      "In case of excessive usage of the E-utilities, NCBI will attempt to contact\n",
      "a user at the email address provided before blocking access to the\n",
      "E-utilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAGTGGAGATGGCGGAGCTGT\n",
      "CAACACGGGAAACCTCACCC\n"
     ]
    }
   ],
   "source": [
    "#SEQ_algoritmos\n",
    "seq_for_al=[]\n",
    "database = 'nucleotide'\n",
    "email= 'rodrigoce9@gmail.com'\n",
    "idlist1= otput_final[0]\n",
    "idlist2= otput_final[1]\n",
    "handle1 = Entrez.efetch(db=database, id=idlist1, rettype=\"gb\") \n",
    "records1 = SeqIO.read(handle1,\"gb\")\n",
    "handle1.close()\n",
    "s1_=records1.seq\n",
    "handle2 = Entrez.efetch(db=database, id=idlist2, rettype=\"gb\") \n",
    "records2 = SeqIO.read(handle2,\"gb\")\n",
    "handle2.close()\n",
    "s2_=records2.seq\n",
    "\n",
    "print(s1_)\n",
    "print(s2_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fecebfa",
   "metadata": {},
   "source": [
    "### Matriz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e162bb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "class Mat:\n",
    "    \n",
    "    def __init__(self, rows, cols):\n",
    "        self.mat = [[0 for c in range(cols)]\n",
    "                    for r in range(rows)]\n",
    "    def numRows (self): return len(self.mat)\n",
    "    def numCols (self): return len(self.mat[0])\n",
    "    def __str__(self):\n",
    "        return '\\n'.join(' '.join(str(val) for val in row)\n",
    "                         for row in self.mat)\n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "    def __getitem__ (self, n):\n",
    "        return self.mat[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "c7bb7c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -   C   A   A   C   A   C   G   G   G   A   A   A   C   C   T   C   A   C   C   C\n",
      "-   0  -4  -8 -12 -16 -20 -24 -28 -32 -36 -40 -44 -48 -52 -56 -60 -64 -68 -72 -76 -80\n",
      "G  -4  -1  -5  -9 -13 -17 -21 -21 -25 -29 -33 -37 -41 -45 -49 -53 -57 -61 -65 -69 -73\n",
      "A  -8  -5   2  -2  -6 -10 -14 -18 -22 -26 -26 -30 -34 -38 -42 -46 -50 -54 -58 -62 -66\n",
      "G -12  -9  -2   1  -3  -7 -11 -11 -15 -19 -23 -27 -31 -35 -39 -43 -47 -51 -55 -59 -63\n",
      "T -16 -13  -6  -3   0  -4  -8 -12 -12 -16 -20 -24 -28 -32 -36 -36 -40 -44 -48 -52 -56\n",
      "G -20 -17 -10  -7  -4  -1  -5  -5  -9  -9 -13 -17 -21 -25 -29 -33 -37 -41 -45 -49 -53\n",
      "G -24 -21 -14 -11  -8  -5  -2  -2  -2  -6 -10 -14 -18 -22 -26 -30 -34 -38 -42 -46 -50\n",
      "A -28 -25 -18 -11 -12  -5  -6  -3  -3  -3  -3  -7 -11 -15 -19 -23 -27 -31 -35 -39 -43\n",
      "G -32 -29 -22 -15 -12  -9  -6  -3   0   0  -4  -4  -8 -12 -16 -20 -24 -28 -32 -36 -40\n",
      "A -36 -33 -26 -19 -16  -9 -10  -7  -4  -1   3  -1  -1  -5  -9 -13 -17 -21 -25 -29 -33\n",
      "T -40 -37 -30 -23 -20 -13 -10 -11  -8  -5  -1   2  -2  -2  -6  -6 -10 -14 -18 -22 -26\n",
      "G -44 -41 -34 -27 -24 -17 -14  -7  -8  -5  -5  -2   1  -3  -3  -7  -7 -11 -15 -19 -23\n",
      "G -48 -45 -38 -31 -28 -21 -18 -11  -4  -5  -6  -6  -3   0  -4  -4  -8  -8 -12 -16 -20\n",
      "C -52 -45 -42 -35 -28 -25 -18 -15  -8  -5  -6  -7  -7   0   3  -1  -1  -5  -5  -9 -13\n",
      "G -56 -49 -46 -39 -32 -29 -22 -15 -12  -5  -6  -7  -8  -4  -1   2  -2  -2  -6  -6 -10\n",
      "G -60 -53 -50 -43 -36 -33 -26 -19 -12  -9  -6  -7  -8  -8  -5  -2   1  -3  -3  -7  -7\n",
      "A -64 -57 -50 -47 -40 -33 -30 -23 -16 -13  -6  -3  -4  -8  -9  -6  -3   4   0  -4  -8\n",
      "G -68 -61 -54 -51 -44 -37 -34 -27 -20 -13 -10  -7  -4  -5  -9 -10  -7   0   3  -1  -5\n",
      "C -72 -65 -58 -55 -48 -41 -34 -31 -24 -17 -14 -11  -8  -1  -2  -6  -7  -4   3   6   2\n",
      "T -76 -69 -62 -59 -52 -45 -38 -35 -28 -21 -18 -15 -12  -5  -2   1  -3  -7  -1   2   5\n",
      "G -80 -73 -66 -63 -56 -49 -42 -35 -32 -25 -22 -19 -16  -9  -6  -3   0  -4  -5  -2   1\n",
      "T -84 -77 -70 -67 -60 -53 -46 -39 -36 -29 -26 -23 -20 -13 -10  -3  -4  -1  -5  -6  -3\n",
      "\n",
      "  - C A A C A C G G G A A A C C T C A C C C\n",
      "- 0 E E E E E E E E E E E E E E E E E E E E\n",
      "G C D D D D D D D D D E E E E E E E E E E E\n",
      "A C D D D E D E E D D D D D E E E E D E E E\n",
      "G C D C D D D D D D D E D D D D D D D D D D\n",
      "T C D C D D D D D D D D D D D D D E E E E E\n",
      "G C D C D D D D D D D E E E E E E D D D D D\n",
      "G C D C D D D D D D D D D D D D D D D D D D\n",
      "A C D D D D D D D D D D D D E E E E D E E E\n",
      "G C D C C D C D D D D D D D D D D D D D D D\n",
      "A C D D D D D D D D D D D D E E E E D E E E\n",
      "T C D C C D C D D D D C D D D D D E E E E E\n",
      "G C D C C D C D D D D C D D D D D D D D D D\n",
      "G C D C C D C D D D D D D D D D D D D D D D\n",
      "C C D C C D C D C C D D D D D D E D E D D D\n",
      "G C C D C C D C D D D D D D C D D D D D D D\n",
      "G C C D C C D C D D D D D D C D D D D D D D\n",
      "A C C D D C D C C C D D D D E D D D D E D D\n",
      "G C C C D C C D D D D C D D D D D D C D D D\n",
      "C C D C D D C D C C C D D D D D E D C D D D\n",
      "T C C C D C C C D C C D D D C D D E E C D D\n",
      "G C C C D C C C D D D D D D C D D D D C D D\n",
      "T C C C D C C C C D C D D D C D D D D D D D\n",
      "\n",
      "\n",
      "-GAGTGGAGATGGCGGAGCTGT\n",
      "CAACACGGGAAACCTCA-C-CC\n"
     ]
    }
   ],
   "source": [
    "#classe nw a funcionar\n",
    "def subst(x, y):\n",
    "    return 3 if x == y else -1 #match de 3 mismatch -1\n",
    "\n",
    "class NW:\n",
    "    def __init__(self, s1, s2, g = -4):\n",
    "        self.s1 = s1 \n",
    "        self.s2 = s2 \n",
    "        self.mat = Mat(len(s1) + 1, len(s2) + 1)\n",
    "        self.tr  = Mat(len(s1) + 1, len(s2) + 1)\n",
    "\n",
    "        for L in range(len(s1)):\n",
    "            self.mat[L + 1][0] = g * (L + 1) \n",
    "            self.tr[L + 1][0]  = 'C' \n",
    "        for C in range(len(s2)):\n",
    "            self.mat[0][C + 1] = g * (C + 1) \n",
    "            self.tr[0][C + 1]  = 'E'\n",
    "\n",
    "        for L, x1 in enumerate(s1):\n",
    "            for C, x2 in enumerate(s2):\n",
    "                possiveis = [\n",
    "                    self.mat[L  ][C    ] + subst(x1, x2),   # Diagonal\n",
    "                    self.mat[L+1][C    ] + g,               # Esquerda\n",
    "                    self.mat[L  ][C + 1] + g,               # Cima\n",
    "                ]\n",
    "                dirs = \"DEC\"\n",
    "                self.mat[L + 1][C + 1] = max(possiveis)\n",
    "                self.tr[L + 1][C + 1] = dirs[possiveis.index(self.mat[L + 1][C + 1])]\n",
    "                \n",
    "    def rebuild(self):\n",
    "        L = len(self.s1)\n",
    "        C = len(self.s2)\n",
    "        S1 = \"\"\n",
    "        S2 = \"\"\n",
    "    \n",
    "        dirs = {\n",
    "            'D' : (-1, -1),\n",
    "            'E' : ( 0, -1),\n",
    "            'C' : (-1,  0)\n",
    "        }\n",
    "        while L > 0 or C > 0:\n",
    "            \n",
    "            DL, DC = dirs[self.tr[L][C]]\n",
    "            if self.tr[L][C] == \"D\":\n",
    "                S1 = self.s1[L - 1] + S1 \n",
    "                S2 = self.s2[C - 1] + S2\n",
    "            elif self.tr[L][C] == \"E\":\n",
    "                S1 = '-' + S1\n",
    "                S2 = self.s2[C - 1] + S2\n",
    "            else:\n",
    "                S1 = self.s1[L - 1] + S1\n",
    "                S2 = '-' + S2        \n",
    "    \n",
    "            L += DL\n",
    "            C += DC\n",
    "\n",
    "        return S1, S2 \n",
    "    def __repr__(self): \n",
    "        cols = \"-\" + self.s2\n",
    "        lins = \"-\" + self.s1\n",
    "        with io.StringIO(\"\") as S:\n",
    "            print(' ', *cols, sep = '   ', file = S)  \n",
    "            for L, linha in zip(lins, self.mat):\n",
    "                print(L, *[f'{x:3d}' for x in linha], file = S)\n",
    "            print(file = S)\n",
    "\n",
    "            print(' ', *cols, file = S) \n",
    "            for L, linha in zip(lins, self.tr):\n",
    "                print(L, *linha, file = S)\n",
    "\n",
    "            return S.getvalue()\n",
    "        \n",
    "alin= NW(s1_,s2_, g= -4)\n",
    "print (alin)\n",
    "print()\n",
    "print(*alin.rebuild(), sep=\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "8e7cfe93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -   C   A   A   C   A   C   G   G   G   A   A   A   C   C   T   C   A   C   C   C\n",
      "-   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "G   0   0   0   0   0   0   0   3   3   3   0   0   0   0   0   0   0   0   0   0   0\n",
      "A   0   0   3   3   0   3   0   0   2   2   6   3   3   0   0   0   0   3   0   0   0\n",
      "G   0   0   0   2   2   0   2   3   3   5   2   5   2   2   0   0   0   0   2   0   0\n",
      "T   0   0   0   0   1   1   0   1   2   2   4   1   4   1   1   3   0   0   0   1   0\n",
      "G   0   0   0   0   0   0   0   3   4   5   1   3   0   3   0   0   2   0   0   0   0\n",
      "G   0   0   0   0   0   0   0   3   6   7   4   0   2   0   2   0   0   1   0   0   0\n",
      "A   0   0   3   3   0   3   0   0   2   5  10   7   3   1   0   1   0   3   0   0   0\n",
      "G   0   0   0   2   2   0   2   3   3   5   6   9   6   2   0   0   0   0   2   0   0\n",
      "A   0   0   3   3   1   5   1   1   2   2   8   9  12   8   4   0   0   3   0   1   0\n",
      "T   0   0   0   2   2   1   4   0   0   1   4   7   8  11   7   7   3   0   2   0   0\n",
      "G   0   0   0   0   1   1   0   7   3   3   0   3   6   7  10   6   6   2   0   1   0\n",
      "G   0   0   0   0   0   0   0   3  10   6   2   0   2   5   6   9   5   5   1   0   0\n",
      "C   0   3   0   0   3   0   3   0   6   9   5   1   0   5   8   5  12   8   8   4   3\n",
      "G   0   0   2   0   0   2   0   6   3   9   8   4   0   1   4   7   8  11   7   7   3\n",
      "G   0   0   0   1   0   0   1   3   9   6   8   7   3   0   0   3   6   7  10   6   6\n",
      "A   0   0   3   3   0   3   0   0   5   8   9  11  10   6   2   0   2   9   6   9   5\n",
      "G   0   0   0   2   2   0   2   3   3   8   7   8  10   9   5   1   0   5   8   5   8\n",
      "C   0   3   0   0   5   1   3   1   2   4   7   6   7  13  12   8   4   1   8  11   8\n",
      "T   0   0   2   0   1   4   0   2   0   1   3   6   5   9  12  15  11   7   4   7  10\n",
      "G   0   0   0   1   0   0   3   3   5   3   0   2   5   5   8  11  14  10   6   3   6\n",
      "T   0   0   0   0   0   0   0   2   2   4   2   0   1   4   4  11  10  13   9   5   2\n",
      "\n",
      "  - C A A C A C G G G A A A C C T C A C C C\n",
      "- 0 C C C C C C C C C C C C C C C C C C C C\n",
      "G E 0 0 0 0 0 0 D D D 0 0 0 0 0 0 0 0 0 0 0\n",
      "A E 0 D D 0 D 0 0 D D D D D 0 0 0 0 D 0 0 0\n",
      "G E 0 0 D D 0 D D D D E D D D 0 0 0 0 D 0 0\n",
      "T E 0 0 0 D D 0 D D D D D D D D D 0 0 0 D 0\n",
      "G E 0 0 0 0 D D D D D D D D D D D D 0 0 0 D\n",
      "G E 0 0 0 0 0 0 D D D D D D 0 D 0 0 D 0 0 0\n",
      "A E 0 D D 0 D 0 0 D D D D D D 0 D 0 D D 0 0\n",
      "G E 0 0 D D 0 D D D D E D D D D 0 D 0 D 0 0\n",
      "A E 0 D D D D C D D D D D D C C C 0 D 0 D 0\n",
      "T E 0 0 D D E D D D D E D D D D D C 0 D 0 D\n",
      "G E 0 0 0 D D D D D D D D D D D D D D 0 D 0\n",
      "G E 0 0 0 0 D D D D D D 0 D D D D D D D 0 D\n",
      "C E D 0 0 D 0 D 0 E D D D 0 D D D D C D D D\n",
      "G E 0 D 0 0 D 0 D D D D D D E D D E D D D D\n",
      "G E 0 0 D 0 0 D D D D D D D 0 D D D D D D D\n",
      "A E 0 D D D D 0 D E D D D D C C 0 D D D D D\n",
      "G E 0 0 D D 0 D D D D D D D D D D 0 E D D D\n",
      "C E D 0 0 D D D D D E D D D D D C D E D D D\n",
      "T E 0 D 0 E D D D D D D D D E D D C C E D D\n",
      "G E 0 0 D 0 D D D D D D D D E D D D D D D D\n",
      "T E 0 0 0 D 0 0 D D D D 0 D D D D D D D D D\n",
      "\n",
      "AGATGGCGGAGCT\n",
      "ACACGGGAAACCT\n"
     ]
    }
   ],
   "source": [
    "class SW:\n",
    "    def __init__(self, s1, s2, gap_penalty, match_score, mismatch_penalty):\n",
    "        self.s1 = s1 \n",
    "        self.s2 = s2 \n",
    "        self.gap_penalty= gap_penalty\n",
    "        self.match_score= match_score\n",
    "        self.mismatch_penalty= mismatch_penalty\n",
    "        self.score = [[0 for j in range(len(s2) + 1)] for i in range(len(s1) + 1)]\n",
    "        self.tr = [[0 for j in range(len(s2) + 1)] for i in range(len(s1) + 1)]\n",
    "       \n",
    "\n",
    "        for L in range(len(s1)): \n",
    "            self.tr[L + 1][0]  = 'E' \n",
    "        for C in range(len(s2)):\n",
    "            self.tr[0][C + 1]  = 'C'\n",
    "                \n",
    "        for i in range(1, len(self.s1) + 1):\n",
    "            for j in range(1, len(self.s2) + 1):\n",
    "                match = self.score[i - 1][j - 1] + (self.match_score if self.s1[i - 1] == self.s2[j - 1] else self.mismatch_penalty)\n",
    "                delete = self.score[i - 1][j] + self.gap_penalty\n",
    "                insert = self.score[i][j - 1] + self.gap_penalty\n",
    "                self.score[i][j] = max(0, match, delete, insert)\n",
    "                possiveis= (match, delete, insert,0)\n",
    "                dirs = 'DEC0'\n",
    "                self.tr[i][j] = dirs[possiveis.index(self.score[i][j])]\n",
    "                \n",
    "                \n",
    "    def rebuild(self):\n",
    "    \n",
    "        L = len(self.s1)\n",
    "        C = len(self.s2)\n",
    "            \n",
    "        max_i, max_j = 0, 0\n",
    "        max_score = 0\n",
    "        for i in range(1, L + 1):\n",
    "            for j in range(1, C + 1):\n",
    "                if self.score[i][j] > max_score:\n",
    "                    max_i, max_j = i, j\n",
    "                    max_score = self.score[i][j]\n",
    "        i, j = max_i, max_j\n",
    "        alignD1= \"\" \n",
    "        alignD2= \"\"\n",
    "        while self.score[i][j] != 0:\n",
    "            current_score = self.score[i][j]\n",
    "            diagonal_score = self.score[i - 1][j - 1]\n",
    "            up_score = self.score[i][j - 1]\n",
    "            left_score = self.score[i - 1][j]\n",
    "\n",
    "            if current_score == diagonal_score + (self.match_score if self.s1[i - 1] == self.s2[j - 1] else self.mismatch_penalty):\n",
    "                alignD1 += self.s1[i - 1]\n",
    "                alignD2 += self.s2[j - 1]\n",
    "                i -= 1\n",
    "                j -= 1\n",
    "            elif current_score == left_score + self.gap_penalty:\n",
    "                alignD1 += self.s1[i - 1]\n",
    "                alignD2 += \"-\"\n",
    "                i -= 1\n",
    "            elif current_score == up_score + self.gap_penalty:\n",
    "                alignD1 += \"-\"\n",
    "                alignD2 += self.s2[j - 1]\n",
    "                j -= 1\n",
    "        \n",
    "                \n",
    "        return alignD1[::-1], alignD2[::-1] \n",
    "    \n",
    "    \n",
    "    \n",
    "    def __repr__(self): \n",
    "        cols = \"-\" + self.s2\n",
    "        lins = \"-\" + self.s1\n",
    "        with io.StringIO(\"\") as S:\n",
    "            print(' ', *cols, sep = '   ', file = S)  \n",
    "            for L, linha in zip(lins, self.score):\n",
    "                print(L, *[f'{x:3d}' for x in linha], file = S)\n",
    "            print(file = S)\n",
    "\n",
    "            print(' ', *cols, file = S) \n",
    "            for L, linha in zip(lins, self.tr ):\n",
    "                print(L, *linha, file = S)\n",
    "\n",
    "            return S.getvalue()\n",
    "\n",
    "\n",
    "alignSW= SW(s1_,s2_,-4,3,-1)\n",
    "print(alignSW)\n",
    "print(*alignSW.rebuild(), sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d15635d",
   "metadata": {},
   "source": [
    "### Multiple align:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "98b600fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---GA-GTGGAGA--TGGCGGAGCTGT\n",
      "CAACACG-GGAAACCT--C--A-C-CC\n",
      "\n",
      "CAAGACGTGGAGACCTGGCGGAGCTGT\n",
      "\n",
      "CAAGACGTGGAGACCTGGCGGAGCTGT\n",
      "--A-A--TCG-G---T--C--A-----\n",
      "\n",
      "CAACACGTGGAAACCT--C--A-C-CC\n",
      "\n",
      "CAACACG-TGGAAACCT--C--A-C-CC\n",
      "-----GGTTGG----------GA----C\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s3='AATCGGTCA'\n",
    "s4='GGTTGGGAC'\n",
    "\n",
    "def consensus(s1_, s2_):\n",
    "    res = \"\"\n",
    "    for x, y in zip(s1_, s2_):\n",
    "        if x == y:\n",
    "            res += x\n",
    "        elif x == '-':\n",
    "            res += y\n",
    "        else:\n",
    "            res += x\n",
    "    #print (res)\n",
    "    return res\n",
    "\n",
    "a1, a2 = NW(s1_, s2_, g = -1).rebuild()\n",
    "print(a1)\n",
    "print(a2)\n",
    "print()\n",
    "m1 = consensus(a1,a2)\n",
    "print(m1)\n",
    "print()\n",
    "m2, a3 = NW(m1, s3, g = -1).rebuild()\n",
    "print(m2,a3, sep=\"\\n\")\n",
    "print()\n",
    "m2= consensus(a2,a3)\n",
    "print(m2)\n",
    "print()\n",
    "m3, a4= NW(m2,s4,g=-1).rebuild()\n",
    "print(m3)\n",
    "print(a4)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4823ed78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
