{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "022bf988",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests  \n",
    "import re\n",
    "from Bio import SeqIO\n",
    "from Bio import Entrez\n",
    "from Bio import Medline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from Bio import SearchIO\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Seq import Seq\n",
    "import mysql.connector as SQLC\n",
    "import mysql.connector\n",
    "from datetime import date\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from Bio.SeqFeature import CompoundLocation\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5b83b1c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "escolha o que quer pesquisar: diabetes\n",
      "escolha o nº de genes que quer obter (máximo 20): 20\n"
     ]
    }
   ],
   "source": [
    "#Extrair ids genebank:\n",
    "\n",
    "data_e_hora_atuais = datetime.now()\n",
    "\n",
    "query= input('escolha o que quer pesquisar: ')\n",
    "\n",
    "\n",
    "try:\n",
    "    def url_get(i):\n",
    "        url_list_id=[]\n",
    "        url = f\"https://www.ncbi.nlm.nih.gov/gene/?term={i}\"\n",
    "        url_list_id.append(url)\n",
    "        return url_list_id\n",
    "    \n",
    "    url_get(query)\n",
    "\n",
    "    content = []\n",
    "    for url in url_get(query):\n",
    "        r = requests.get(url)\n",
    "        content.append(r.content)\n",
    "\n",
    "    for c in content:\n",
    "        soup = BeautifulSoup(c, 'html.parser')\n",
    "        a= soup.get_text()\n",
    "\n",
    "    existe = re.findall(r\"ID:\\s+\\d*(?=\\D)\", a, re.DOTALL)\n",
    "\n",
    "    c= ', '.join(existe)\n",
    "    h= c.replace('ID: ','')\n",
    "    IDS= h.split(', ')\n",
    "\n",
    "    n_gene= IDS[0:1+(int(input('escolha o nº de genes que quer obter (máximo 20): ')))]\n",
    "\n",
    "    n_genes = []\n",
    "    seen = set()\n",
    "    for item in n_gene:\n",
    "        if item not in seen:\n",
    "            seen.add(item)\n",
    "            n_genes.append(item)\n",
    "\n",
    "    numero_genes= len(n_genes)\n",
    "\n",
    "    if n_genes == ['']:\n",
    "        print()\n",
    "        print('0 resultados para a sua pesquisa, pesquise de novo.')\n",
    "\n",
    "except:\n",
    "    ('0 resultados para a sua pesquisa, pesquise de novo.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e05384b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concluido\n"
     ]
    }
   ],
   "source": [
    "#Extrair ids ncbi:\n",
    "Ids=[]\n",
    "database = 'nucleotide'\n",
    "email= 'rodrigoce9@gmail.com'\n",
    "idlist= n_genes\n",
    "handle = Entrez.efetch(db=database, id=idlist, rettype=\"gb\") \n",
    "records = list(SeqIO.parse(handle,\"gb\"))\n",
    "handle.close()\n",
    "for info in records:\n",
    "    Ids.append(info.id)\n",
    "    \n",
    "if Ids == ['']:\n",
    "    print('0 resultados para a sua pesquisa, pesquise de novo.')\n",
    "        \n",
    "#Extrair description NCBI:\n",
    "description=[]\n",
    "database = 'nucleotide'\n",
    "email= 'rodrigoce9@gmail.com'\n",
    "idlist= n_genes\n",
    "handle = Entrez.efetch(db=database, id=idlist, rettype=\"gb\") \n",
    "records = list(SeqIO.parse(handle,\"gb\"))\n",
    "handle.close()\n",
    "for info in records:\n",
    "    description.append(info.description)\n",
    "\n",
    "#organismos\n",
    "Organismos=[]\n",
    "database = 'nucleotide'\n",
    "email= 'rodrigoce9@gmail.com'\n",
    "idlist= n_genes\n",
    "handle = Entrez.efetch(db=database, id=idlist, rettype=\"gb\") \n",
    "records = list(SeqIO.parse(handle,\"gb\"))\n",
    "handle.close()\n",
    "for info in records:\n",
    "    Organismos.append(info.annotations['organism'])\n",
    "    \n",
    "#SEQ\n",
    "seqss=[]\n",
    "database = 'nucleotide'\n",
    "email= 'rodrigoce9@gmail.com'\n",
    "idlist= n_genes\n",
    "handle = Entrez.efetch(db=database, id=idlist, rettype=\"gb\") \n",
    "records = list(SeqIO.parse(handle,\"gb\"))\n",
    "handle.close()\n",
    "for info in records:\n",
    "    seqs= (f'{info.seq[0:10]}...{info.seq[-10:]}')\n",
    "    seqss.append(seqs)\n",
    "\n",
    "#percentagem de nucle:\n",
    "Adenina=[]\n",
    "database = 'nucleotide'\n",
    "email= 'rodrigoce9@gmail.com'\n",
    "idlist= n_genes\n",
    "handle = Entrez.efetch(db=database, id=idlist, rettype=\"gb\") \n",
    "records = list(SeqIO.parse(handle,\"gb\"))\n",
    "handle.close()\n",
    "for info in records:\n",
    "    c=info.seq\n",
    "    count= c.count('A')\n",
    "    perc= int(count/len(c)*100)\n",
    "    Adenina.append(perc)\n",
    "\n",
    "Citosina=[]\n",
    "database = 'nucleotide'\n",
    "email= 'rodrigoce9@gmail.com'\n",
    "idlist= n_genes\n",
    "handle = Entrez.efetch(db=database, id=idlist, rettype=\"gb\") \n",
    "records = list(SeqIO.parse(handle,\"gb\"))\n",
    "handle.close()\n",
    "for info in records:\n",
    "    c=info.seq\n",
    "    count= c.count('C')\n",
    "    perc= int(count/len(c)*100)\n",
    "    Citosina.append(perc)\n",
    "\n",
    "Guanina=[]\n",
    "database = 'nucleotide'\n",
    "email= 'rodrigoce9@gmail.com'\n",
    "idlist= n_genes\n",
    "handle = Entrez.efetch(db=database, id=idlist, rettype=\"gb\") \n",
    "records = list(SeqIO.parse(handle,\"gb\"))\n",
    "handle.close()\n",
    "for info in records:\n",
    "    c=info.seq\n",
    "    count= c.count('G')\n",
    "    perc= int(count/len(c)*100)\n",
    "    Guanina.append(perc)\n",
    "\n",
    "Timina=[]\n",
    "database = 'nucleotide'\n",
    "email= 'rodrigoce9@gmail.com'\n",
    "idlist= n_genes\n",
    "handle = Entrez.efetch(db=database, id=idlist, rettype=\"gb\") \n",
    "records = list(SeqIO.parse(handle,\"gb\"))\n",
    "handle.close()\n",
    "for info in records:\n",
    "    c=info.seq\n",
    "    count= c.count('T')\n",
    "    perc= int(count/len(c)*100)\n",
    "    Timina.append(perc)\n",
    "    \n",
    "#data\n",
    "dates=[]\n",
    "database = 'nucleotide'\n",
    "email= 'rodrigoce9@gmail.com'\n",
    "idlist= n_genes\n",
    "handle = Entrez.efetch(db=database, id=idlist, rettype=\"gb\") \n",
    "records = list(SeqIO.parse(handle,\"gb\"))\n",
    "handle.close()\n",
    "for info in records:\n",
    "    dates.append(info.annotations['date'])\n",
    "\n",
    "#len(SEQ)\n",
    "database = 'nucleotide'\n",
    "email= 'rodrigoce9@gmail.com'\n",
    "idlist= n_genes\n",
    "handle = Entrez.efetch(db=database, id=idlist, rettype=\"gb\") \n",
    "records = list(SeqIO.parse(handle,\"gb\"))\n",
    "handle.close()\n",
    "tam=[]\n",
    "for info in records:\n",
    "    tam.append(len(info.seq))\n",
    "    \n",
    "    # buscar info pubmed\n",
    "try:\n",
    "    def url_get_id(i):\n",
    "        url_list= [ ]\n",
    "        for id in i:\n",
    "            url = \"https://www.ncbi.nlm.nih.gov/nuccore/{}\".format( id )\n",
    "            url_list.append(url)\n",
    "        return url_list\n",
    "    link_genebank= url_get_id(Ids)\n",
    "    #print(link_genebank)\n",
    "\n",
    "    content_id = []\n",
    "    for url in url_get_id(Ids):\n",
    "        r_id = requests.get(url)\n",
    "        content_id.append(r_id.content)\n",
    "\n",
    "    from bs4 import BeautifulSoup\n",
    "    listas=[]\n",
    "\n",
    "    for c in content_id:\n",
    "        soup_id = BeautifulSoup(c, 'html.parser')\n",
    "\n",
    "        lines = soup_id.find_all('meta', {'name':\"ncbi_uidlist\"} )\n",
    "\n",
    "        id = \"\"\n",
    "        url = \"\"\n",
    "        for line in lines:\n",
    "            if 'content' in line.attrs:\n",
    "                id = line.attrs['content']\n",
    "        if id:\n",
    "            url = \"https://www.ncbi.nlm.nih.gov/sviewer/viewer.fcgi?id={}&db=nuccore&report=genbank&conwithfeat=on&hide-cdd=on&retmode=text&maxdownloadsize=5000000\".format(id)\n",
    "        r2 = requests.get(url)\n",
    "        r4= r2.content.decode('utf-8')\n",
    "        listas.append(r4)\n",
    "\n",
    "    cc= ', '.join(listas)\n",
    "    er= cc.replace('//','')\n",
    "    final= er.split(', ')\n",
    "\n",
    "    #criar dicionário de ids ncbi e ids pubmed\n",
    "    output_dict = {}\n",
    "    for x in final:\n",
    "        version = re.search(r'VERSION\\s+(.*?)\\s', x)\n",
    "        pubmed = re.search(r'PUBMED\\s+(.*?)\\s', x)\n",
    "        if version:\n",
    "            versionf=version.group(1)\n",
    "            output_dict.setdefault(version.group(1), [])\n",
    "        if pubmed:\n",
    "            output_dict[versionf].append(pubmed.group(1))\n",
    "except:\n",
    "    print()\n",
    "    print(\"0 resultados na Pubmed em realção à sua query\")\n",
    "    \n",
    "#Criar Listas só com ids ncbi e ids pubmed\n",
    "id_ncbii = []\n",
    "ID_PUB = []\n",
    "for key, vals in output_dict.items():\n",
    "    if vals:\n",
    "        for val in vals:\n",
    "            id_ncbii.append(key)\n",
    "            ID_PUB.append(val)\n",
    "    else:\n",
    "        id_ncbii.append(key)\n",
    "        ID_PUB.append(\"N/A\")\n",
    "\n",
    "new_list_ = []\n",
    "seen = set()\n",
    "for item in ID_PUB:\n",
    "    if item not in seen:\n",
    "        seen.add(item)\n",
    "        new_list_.append(item)\n",
    "\n",
    "print(\"Concluido\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "949a591d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concluido\n"
     ]
    }
   ],
   "source": [
    "#Extrair informação de artigos\n",
    "try:\n",
    "    titles=[]\n",
    "    authors=[]\n",
    "    source=[]\n",
    "    affiliation=[]\n",
    "    database = 'PubMed'\n",
    "    email= 'rodrigoce9@gmail.com'\n",
    "    idlist= new_list_\n",
    "    counter = 0\n",
    "    for i in idlist:\n",
    "        if i!= \"N/A\":\n",
    "            handle = Entrez.efetch(db=database, id=i, rettype=\"medline\", retmode=\"text\") \n",
    "            records = Medline.parse(handle)\n",
    "            for info in records:\n",
    "                titles.append(info.get(\"TI\", [\"N/A\"]))\n",
    "                authors_string = info.get(\"AU\", [\"N/A\"])\n",
    "                if len(authors_string) > 5:\n",
    "                    authors_h = authors_string[0:5]\n",
    "                    authors.append(authors_h)\n",
    "                else:\n",
    "                    authors.append(authors_string) \n",
    "                source.append(info.get(\"SO\", [\"N/A\"]))\n",
    "                affiliation_string= info.get(\"AD\", [\"N/A\"])\n",
    "                if len(affiliation_string) > 5:\n",
    "                    affiliation_h = affiliation_string[0:5]\n",
    "                    affiliation.append(affiliation_h)\n",
    "                else:\n",
    "                    affiliation.append(affiliation_string)\n",
    "                counter += 1\n",
    "        else:\n",
    "            titles.append([\"N/A\"])\n",
    "            authors.append([\"N/A\"])\n",
    "            source.append([\"N/A\"])\n",
    "            affiliation.append([\"N/A\"])\n",
    "            counter += 1\n",
    "except:\n",
    "    print('artigos não encontrados por um possivel bug de id')\n",
    "    \n",
    "#agrupar titles\n",
    "titles = [ [title] for title in titles]\n",
    "\n",
    "# agrupar dois\n",
    "doi_list = []\n",
    "for x in source:\n",
    "    match = re.search(\"doi: (.*)\", str(x))\n",
    "    if match:\n",
    "        doi_list.append(match.group(1))\n",
    "    else:\n",
    "        doi_list.append(\"N/A\")\n",
    "        \n",
    "#agrupar authors\n",
    "id_authors_dict = {i: authors[counter] if i != \"N/A\" else [\"N/A\"] for counter, i in enumerate(idlist)}        \n",
    "        \n",
    "pubmed_list = []\n",
    "authors_list = []\n",
    "for key, vals in id_authors_dict.items():\n",
    "    if vals:\n",
    "        for val in vals:\n",
    "            pubmed_list.append(key)\n",
    "            authors_list.append(val)\n",
    "\n",
    "new_list_authors= []\n",
    "seen = set()\n",
    "for item in authors_list:\n",
    "    if item not in seen:\n",
    "        seen.add(item)\n",
    "        new_list_authors.append(item)\n",
    "\n",
    "#agrupar affi\n",
    "single_affiliation_list = []\n",
    "for i in affiliation:\n",
    "    single_affiliation_list.extend(i)\n",
    "    \n",
    "\n",
    "id_affiliation_dict = {i: [single_affiliation_list[counter]] if i != \"N/A\" else [\"N/A\"] for counter, i in enumerate(idlist)}\n",
    "\n",
    "pubmed_affi_list = []\n",
    "affi_list = []\n",
    "for key, vals in id_affiliation_dict.items():\n",
    "    if vals:\n",
    "        for val in vals:\n",
    "            pubmed_affi_list.append(key)\n",
    "            affi_list.append(val)\n",
    "    else:\n",
    "        pubmed_affi_list.append(key)\n",
    "        affi_list.append([\"N/A\"])\n",
    "\n",
    "new_list_affi= []\n",
    "seen = set()\n",
    "for item in single_affiliation_list :\n",
    "    if item not in seen:\n",
    "        seen.add(item)\n",
    "        new_list_affi.append(item)\n",
    "\n",
    "def url_get_id_p(string):\n",
    "    url_list_p=[ ]\n",
    "    url_id_p= \"https://www.uniprot.org/uniprotkb/{}/entry\".format(str(string))\n",
    "    url_list_p.append(url_id_p)\n",
    "    return ''.join(url_list_p)\n",
    "\n",
    "# protein_id - PROT_ID \n",
    "list_pro=[]\n",
    "database = 'nucleotide'\n",
    "email= 'rodrigoce9@gmail.com'\n",
    "idlist= n_genes\n",
    "handle = Entrez.efetch(db=database, id=idlist, rettype=\"gb\") \n",
    "records = list(SeqIO.parse(handle,\"gb\"))\n",
    "handle.close()\n",
    "for info in records:\n",
    "    for i in info.features:\n",
    "        if i.type == \"CDS\":\n",
    "            pro= str(i.qualifiers[\"protein_id\"])\n",
    "            list_pro.append(pro)\n",
    "div= ', '.join(list_pro)\n",
    "h= div.replace(\"['\",'')\n",
    "hh= h.replace(\"']\",'')\n",
    "ID_PROT= hh.split(', ')\n",
    "\n",
    "#result_dic = {Ids, ID_PROT} - \n",
    "result_dict = {}\n",
    "database = 'nucleotide'\n",
    "email= 'rodrigoce9@gmail.com'\n",
    "idlist=Ids\n",
    "for ids in idlist:\n",
    "    list_pro=[]\n",
    "#     print( ids)\n",
    "    handle = Entrez.efetch(db=database, id=ids, rettype=\"gb\") \n",
    "    records = list(SeqIO.parse(handle,\"gb\"))\n",
    "    handle.close()\n",
    "    for info in records:\n",
    "        list_pro.append(info.id)\n",
    "        for i in info.features:\n",
    "            if i.type == \"CDS\":\n",
    "                pro= str(i.qualifiers[\"protein_id\"])\n",
    "                list_pro.append(pro)\n",
    "        if len(list_pro)==1: #if no protein_id was found\n",
    "            result_dict[info.id] = \"N/A_CDS\"\n",
    "        else:\n",
    "            list_pro = [x.replace(\"['\",'').replace(\"']\",'') for x in list_pro]\n",
    "            result_dict[info.id] = ', '.join(list_pro[1:])\n",
    "#key: id_genebank; values: ID_PROT\n",
    "\n",
    "def dict_to_list(d, delimiter=','): #transforms dictionary to list\n",
    "    new_list = []\n",
    "    for k, v in d.items():\n",
    "        if isinstance(v, str):\n",
    "            values = v.split(delimiter)\n",
    "            for val in values:\n",
    "                new_list.append([k, val.strip()])\n",
    "        else:\n",
    "            new_list.append([k, v])\n",
    "    return new_list\n",
    "dict_list=dict_to_list(result_dict)\n",
    "\n",
    "\n",
    "from collections import OrderedDict\n",
    "def get_CDS_info(result_dict): #gets info for CDS [ID_CDS, location, Translation]\n",
    "    database = 'nucleotide'\n",
    "    email= 'rodrigoce9@gmail.com'\n",
    "    Entrez.email = email\n",
    "    cds_location_list = []\n",
    "    several_location = []\n",
    "    record_types={}\n",
    "    processed_i = set()\n",
    "    for i, value in result_dict.items():\n",
    "        if i in processed_i:\n",
    "            continue\n",
    "        if value == 'N/A_CDS':\n",
    "            cds_location = ['N/A_CDS', 'N/A', 'N/A']\n",
    "            cds_location_list.append(cds_location)\n",
    "        else:\n",
    "            handle = Entrez.efetch(db=database, id=i, rettype=\"gb\") \n",
    "            records = list(SeqIO.parse(handle,\"gb\"))\n",
    "            handle.close()\n",
    "            for info in records:\n",
    "                for i in info.features:\n",
    "                    if i.type == \"CDS\":\n",
    "                        cds_location = []\n",
    "                        i_d = str(i.qualifiers[\"protein_id\"])\n",
    "                        translation =  str(i.qualifiers[\"translation\"])\n",
    "                        cds_location.append(i_d)\n",
    "                        if isinstance(i.location, CompoundLocation):\n",
    "                            for sub_location in i.location.parts:\n",
    "                                several_location.append(\"[{} : {}]\".format(sub_location.start, sub_location.end))\n",
    "                            cds_location.append(several_location)\n",
    "                            cds_location.append(translation)\n",
    "                        else:\n",
    "                            cds_location.append(\"[{} : {}]\".format(i.location.start, i.location.end))\n",
    "                            cds_location.append(translation)\n",
    "                        cds_location_list.append(cds_location)      \n",
    "                processed_i.add(i)\n",
    "            handle.close()\n",
    "    return cds_location_list   \n",
    "\n",
    "WEBSITE_API = \"https://rest.uniprot.org\"\n",
    "fields = [\"accession\",\"organism_name\",\"protein_name\",\"cc_subcellular_location\",\"cc_function\", \"sequence\"]\n",
    "def get_url(url, **kwargs):\n",
    "    response = requests.get(url, **kwargs);\n",
    "    if not response.ok:\n",
    "        print(response.text)\n",
    "        response.raise_for_status()\n",
    "        sys.exit()\n",
    "    return response\n",
    "\n",
    "#get list of [ID_Uniprot, Subcellular location, Function, Sequence, Sequence length]\n",
    "def get_field_for_id(ID_PROT, field): \n",
    "    response = get_url(\"{}/uniprotkb/search?query={}&fields={}&size=1&format=tsv\".format(WEBSITE_API,ID_PROT,field))\n",
    "    return str(response.content)\n",
    "\n",
    "try:\n",
    "    def get_list_uniprot(ID_PROT, result_dict):\n",
    "        results = []\n",
    "        result = []\n",
    "        tmp= []\n",
    "        easy=dict_to_list(result_dict)\n",
    "        for first_index, first_value in easy:\n",
    "            tmp= []\n",
    "            if first_value != 'N/A_CDS':\n",
    "                for field in fields:\n",
    "                    result = get_field_for_id(first_value, field)\n",
    "                    tmp.append(result)\n",
    "            else:\n",
    "                result = ['N/A_Uniprot']\n",
    "                tmp.append(result)\n",
    "            results.append(tmp)   \n",
    "        uniprot_final_list=[]\n",
    "        for index, values in enumerate(results):\n",
    "            uniprot_list=[]\n",
    "            n_a = re.search(r'(N/A_Uniprot)', str(values), re.DOTALL)\n",
    "            if len (values)==1:\n",
    "                if n_a:\n",
    "                    uniprot_list.append(n_a.group(1))\n",
    "                    tmp_list='N/A','N/A','N/A','N/A'\n",
    "                    uniprot_list.extend(tmp_list)\n",
    "            else:\n",
    "                for i in values:\n",
    "                    entry = re.search(r'b\\'Entry\\\\n(.+?(?=\\\\n\\'))', str(i), re.DOTALL)\n",
    "                    function = re.match( r'b\\'Function \\[CC\\]\\\\n.{9} (.+?(?=\\\\n\\'))', str(i), re.DOTALL )\n",
    "                    location_exist = re.search( r'b\\'Subcellular location \\[CC\\]\\\\nSUBCELLULAR LOCATION: (.+?(?=\\\\n\\'))', str(i), re.DOTALL )\n",
    "                    location_notexist = re.search( r'b\\'Subcellular location \\[CC\\]\\\\n\\\\n\\'',str(i), re.DOTALL )   \n",
    "                    sequence = re.search(r'b\\'Sequence\\\\n(.+?(?=\\\\n\\'))', str(i), re.DOTALL)\n",
    "                    if entry:\n",
    "                        ent=entry.group(1)\n",
    "                        uniprot_list.append(entry.group(1))            \n",
    "                    if function:\n",
    "                        uniprot_list.append(function.group(1))\n",
    "                    if location_exist:\n",
    "                        uniprot_list.append(location_exist.group(1))\n",
    "                    if location_notexist:\n",
    "                        uniprot_list.append(\"N/A\")\n",
    "                    if sequence:\n",
    "                        uniprot_list.append(sequence.group(1))\n",
    "                        uniprot_list.append(len(sequence.group(1)))\n",
    "                        uniprot_list.append(url_get_id_p(ent))\n",
    "\n",
    "            if len(uniprot_list) < 6: #sometimes, there is no function associated\n",
    "                uniprot_list.insert(2, 'N/A')\n",
    "            uniprot_final_list.append(uniprot_list)\n",
    "\n",
    "        return uniprot_final_list\n",
    "    get_Uniprot=get_list_uniprot(ID_PROT,result_dict)    \n",
    "except:\n",
    "    print(\"A informação foi apagada \")\n",
    "    \n",
    "#[idgenebank, protein_id, id do uniprot] \n",
    "#joins to final list [idgenebank, ID_PRO, ID_Uniprot]\n",
    "def join_ids_CDS(lista, uniprotID): \n",
    "    join_list_all = []\n",
    "    for key, value in lista:\n",
    "        join_list = []\n",
    "        join_list.append(key)\n",
    "        join_list.append(value)\n",
    "        join_list_all.append(join_list) \n",
    "    for index, values in enumerate(uniprotID):\n",
    "        join_list_all[index].append(uniprotID[index][0])\n",
    "    return join_list_all\n",
    "join_ids=join_ids_CDS(dict_list,get_list_uniprot(ID_PROT, result_dict))\n",
    "\n",
    "\n",
    "def join_lists(list1, list2): #joins to final list [idgenebank, ID_PRO, ID_Uniprot,location, Translation]\n",
    "    final_result =[]\n",
    "    list_tmp=[]\n",
    "    tmp=''\n",
    "    for item, value in enumerate(list1):\n",
    "        result = []\n",
    "        string_item = str(list2[item][0])\n",
    "        string_item = string_item.replace(\"[\",\"\").replace(\"]\",\"\").replace(\"'\",\"\")\n",
    "        if list1[item][1] == string_item:\n",
    "            result.append(list1[item] + list2[item][1:])\n",
    "            tmp=list1[item][0]\n",
    "        elif list1[item][0] == tmp:\n",
    "            list_tmp = []\n",
    "            list_tmp.append(tmp)\n",
    "            list_tmp.append(list1[item][1])\n",
    "            list_tmp.append(list1[item][2])\n",
    "            result.append(list_tmp + list2[item][1:])\n",
    "        else:\n",
    "            result.append(list1[item])\n",
    "        final_result.extend(result)\n",
    "    return final_result\n",
    "join_CDS=join_lists(join_ids, get_CDS_info(result_dict))\n",
    "\n",
    "def count_(genes):\n",
    "    return len(genes)\n",
    "count_(Ids)\n",
    "count_(ID_PROT)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Concluido\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "da3ff3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete de tudo \n",
    "\n",
    "DataBase = SQLC.connect(\n",
    "    host =\"geo.di.uminho.pt\",\n",
    "    user =\"bioinformatica\",\n",
    "    password =\"20221207\",\n",
    "    database =\"AP_db_KRG\"\n",
    ")\n",
    "DataBase.autocommit = True # allows the change be done\n",
    "\n",
    "Cursor = DataBase.cursor()\n",
    "try:\n",
    "        \n",
    "        a= \"delete from PubMed_Affiliation\"\n",
    "        Z= \"delete from PubMed_Authors\"\n",
    "        b= \"delete from Affiliation\"\n",
    "        c= \"delete from Authors\"\n",
    "        d= \"delete from gene_PubMed\"\n",
    "        e= \"delete from PubMed\"\n",
    "        f= \"delete from CDS\"\n",
    "        g= \"delete from Uniprot\"\n",
    "        h= \"delete from Gene\"\n",
    "        #i= \"delete from History\"     \n",
    "        \n",
    "        Cursor.execute(a)\n",
    "        Cursor.execute(Z)\n",
    "        Cursor.execute(b)\n",
    "        Cursor.execute(c)\n",
    "        Cursor.execute(d)\n",
    "        Cursor.execute(e)\n",
    "        Cursor.execute(f)\n",
    "        Cursor.execute(g)\n",
    "        Cursor.execute(h)\n",
    "        #Cursor.execute(i)\n",
    "        \n",
    "except mysql.connector.Error as e:\n",
    "    print(\"Erro na escrita na base de dados: {}\".format(e) )    \n",
    "finally:\n",
    "    DataBase.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "40bbca2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concluido\n"
     ]
    }
   ],
   "source": [
    "#Povoação \"History\"\n",
    "\n",
    "DataBase = SQLC.connect(\n",
    "    host =\"geo.di.uminho.pt\",\n",
    "    user =\"bioinformatica\",\n",
    "    password =\"20221207\",\n",
    "    database =\"AP_db_KRG\"\n",
    ")\n",
    "DataBase.autocommit = True # allows the change be done\n",
    "\n",
    "Cursor = DataBase.cursor()\n",
    "try:\n",
    "    sql1= \"INSERT INTO History (search, Genes_number_input, Day, Genes_number_NCBI, Protein_number  )   VALUES (%s, %s, %s, %s, %s)\"\n",
    "    val1=(query, numero_genes, data_e_hora_atuais, count_(Ids), count_(ID_PROT) )\n",
    "    Cursor.execute(sql1,val1)\n",
    "    \n",
    "except mysql.connector.Error as e:\n",
    "    print(\"Erro na escrita na base de dados: {}\".format(e) ) \n",
    "    \n",
    "search_id=[]\n",
    "try:\n",
    "    sql2= \"Select ID_search FROM History\"\n",
    "    Cursor.execute(sql2)\n",
    "    for row in Cursor:\n",
    "        search_id.append(str(row)) \n",
    "        \n",
    "except mysql.connector.Error as e:\n",
    "    print(\"Erro na escrita na base de dados: {}\".format(e) )    \n",
    "    \n",
    "div= ', '.join(search_id)\n",
    "h= div.replace(\"(\",'')\n",
    "hh= h.replace(\",)\",'')\n",
    "SEARCH_ID= hh.split(', ')\n",
    "Hist= SEARCH_ID[-1]\n",
    "\n",
    "#Povoação \"Gene\"-\n",
    "\n",
    "des = (description)\n",
    "\n",
    "try:\n",
    "    for index, value in enumerate(Ids):\n",
    "       \n",
    "        sql3= \"INSERT INTO Gene (ID_genebank, Description, Organism, sequence, Date_publish, length, Adenina, Citosina, Guanina, Timina, Link, ID_search) VALUES ( %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\"\n",
    "        val3=(value, des[index], Organismos[index], seqss[index], dates[index], tam[index], Adenina[index], Citosina[index], Guanina[index], Timina[index], link_genebank[index], Hist)\n",
    "\n",
    "        Cursor.execute(sql3,val3)\n",
    "\n",
    "except mysql.connector.Error as e:\n",
    "    print(\"Erro na escrita na base de dados: {}\".format(e) )    \n",
    "    \n",
    "#Povoar \"PubMed\"\n",
    "\n",
    "try:\n",
    "    for index, value in enumerate(new_list_):\n",
    "        sql4= \"INSERT INTO PubMed (ID_PumMed, title, Doi_number) VALUES (%s, %s, %s)\"\n",
    "        val4=(str(new_list_[index]), str(titles[index]), str(doi_list[index]) )\n",
    "        Cursor.execute(sql4,val4)\n",
    "\n",
    "except mysql.connector.Error as e:\n",
    "    print(\"Erro na escrita na base de dados: {}\".format(e) )    \n",
    "\n",
    "    \n",
    "#retirar os valores AI de pubmed\n",
    "ID_AI=[]\n",
    "\n",
    "try:\n",
    "    sql5= \"Select ID_AI_PubMed FROM PubMed\"\n",
    "    Cursor.execute(sql5)\n",
    "    for row in Cursor:\n",
    "        ID_AI.append(str(row))       \n",
    "except mysql.connector.Error as e:\n",
    "    print(\"Erro na escrita na base de dados: {}\".format(e) )    \n",
    "      \n",
    "div_= ', '.join(ID_AI)\n",
    "h_= div_.replace(\"(\",'')\n",
    "hh_= h_.replace(\",)\",'')\n",
    "SEARCH_ID_= hh_.split(', ')\n",
    "#print(SEARCH_ID_)\n",
    "\n",
    "#Povação \"Gene-Pubmed\"\n",
    "number_map = {}\n",
    "next_number = int(SEARCH_ID_[0])\n",
    "relation = []\n",
    "for number in ID_PUB:\n",
    "    if number not in number_map:\n",
    "        number_map[number] = next_number\n",
    "        next_number += 1\n",
    "    relation.append(number_map[number])\n",
    "    \n",
    "try:\n",
    "    for index, value in enumerate(id_ncbii):\n",
    "        \n",
    "        sql6= \"INSERT INTO gene_PubMed (ID_genebank, ID_AI_PubMed) VALUES (%s, %s)\"\n",
    "        val6=(id_ncbii[index], relation[index])\n",
    "    \n",
    "        Cursor.execute(sql6,val6)\n",
    "\n",
    "except mysql.connector.Error as e:\n",
    "    print(\"Erro na escrita na base de dados: {}\".format(e) )    \n",
    "    \n",
    "#Povação \"authors\"\n",
    "try:\n",
    "    for index, value in enumerate(new_list_authors):\n",
    "        \n",
    "        sql7= \"INSERT INTO Authors (Name) VALUES (%s)\"\n",
    "        val7=(new_list_authors[index],)\n",
    "    \n",
    "        Cursor.execute(sql7,val7)\n",
    "\n",
    "except mysql.connector.Error as e:\n",
    "    print(\"Erro na escrita na base de dados: {}\".format(e) )    \n",
    "\n",
    "#retirar os valores AI de authors\n",
    "ID_AI_Authors=[]\n",
    "\n",
    "try:\n",
    "    sql8= \"Select ID_Authors FROM Authors\"\n",
    "    Cursor.execute(sql8)\n",
    "    for row in Cursor:\n",
    "        ID_AI_Authors.append(str(row))       \n",
    "except mysql.connector.Error as e:\n",
    "    print(\"Erro na escrita na base de dados: {}\".format(e) )    \n",
    "    \n",
    "div_Authors= ', '.join(ID_AI_Authors)\n",
    "h_Authors= div_Authors.replace(\"(\",'')\n",
    "hh_Authors= h_Authors.replace(\",)\",'')\n",
    "SEARCH_ID_Authors= hh_Authors.split(', ')\n",
    "#print(SEARCH_ID_Authors)\n",
    "\n",
    "#Povação \"Pubmed-Authors\"\n",
    "number_map_ = {}\n",
    "next_number = int(SEARCH_ID_Authors[0])\n",
    "output_authors = []\n",
    "for number in authors_list:\n",
    "    if number not in number_map_:\n",
    "        number_map_[number] = next_number\n",
    "        next_number += 1\n",
    "    output_authors.append(number_map_[number])\n",
    "\n",
    "number_map_pub = {}\n",
    "next_number = int(SEARCH_ID_[0])\n",
    "output_pub = []\n",
    "for number in pubmed_list:\n",
    "    if number not in number_map_pub:\n",
    "        number_map_pub[number] = next_number\n",
    "        next_number += 1\n",
    "    output_pub.append(number_map_pub[number])\n",
    "\n",
    "try:\n",
    "    for index, value in enumerate(output_pub):\n",
    "        \n",
    "        sql9= \"INSERT INTO PubMed_Authors (ID_AI_PubMed, ID_Authors) VALUES (%s, %s)\"\n",
    "        val9=(str(output_pub[index]),str(output_authors[index]))\n",
    "    \n",
    "        Cursor.execute(sql9,val9)\n",
    "\n",
    "except mysql.connector.Error as e:\n",
    "    print(\"Erro na escrita na base de dados: {}\".format(e) )    \n",
    "    \n",
    "#Povação \"affi\"\n",
    "\n",
    "try:\n",
    "    for index, value in enumerate(new_list_affi):\n",
    "        \n",
    "        sql10= \"INSERT INTO Affiliation (Info) VALUES (%s)\"\n",
    "        val10=(new_list_affi[index],)\n",
    "    \n",
    "        Cursor.execute(sql10,val10)\n",
    "\n",
    "except mysql.connector.Error as e:\n",
    "    print(\"Erro na escrita na base de dados: {}\".format(e) )    \n",
    "    \n",
    "#retirar os valores AI de affi\n",
    "ID_AI_Affiliation=[]\n",
    "\n",
    "try:\n",
    "    sql11= \"Select ID_Affiliation FROM Affiliation\"\n",
    "    Cursor.execute(sql11)\n",
    "    for row in Cursor:\n",
    "        ID_AI_Affiliation.append(str(row))       \n",
    "except mysql.connector.Error as e:\n",
    "    print(\"Erro na escrita na base de dados: {}\".format(e) )    \n",
    "    \n",
    "div_Affiliation= ', '.join(ID_AI_Affiliation)\n",
    "h_Affiliation= div_Affiliation.replace(\"(\",'')\n",
    "hh_Affiliation= h_Affiliation.replace(\",)\",'')\n",
    "SEARCH_ID_Affiliation= hh_Affiliation.split(', ')\n",
    "#print(SEARCH_ID_Affiliation)\n",
    "\n",
    "#Povação \"Pubmed-Affiliation\"\n",
    "number_map_affi_pub = {}\n",
    "next_number = int(SEARCH_ID_[0])\n",
    "output_pub_affi = []\n",
    "for number in pubmed_affi_list:\n",
    "    if number not in number_map_affi_pub:\n",
    "        number_map_affi_pub[number] = next_number\n",
    "        next_number += 1\n",
    "    output_pub_affi.append(number_map_affi_pub[number])\n",
    "    \n",
    "number_map_affi = {}\n",
    "next_number = int(SEARCH_ID_Affiliation[0])\n",
    "output_affi = []\n",
    "for number in affi_list:\n",
    "    if number not in number_map_affi:\n",
    "        number_map_affi[number] = next_number\n",
    "        next_number += 1\n",
    "    output_affi.append(number_map_affi[number])\n",
    "\n",
    "try:\n",
    "    for index, value in enumerate(output_pub_affi):\n",
    "        \n",
    "        sql12= \"INSERT INTO PubMed_Affiliation (ID_AI_PubMed, ID_Affiliation) VALUES (%s, %s)\"\n",
    "        val12=(str(output_pub_affi[index]),str(output_affi[index]))\n",
    "    \n",
    "        Cursor.execute(sql12,val12)\n",
    "\n",
    "except mysql.connector.Error as e:\n",
    "    print(\"Erro na escrita na base de dados: {}\".format(e) )    \n",
    "\n",
    "#Povoação \"Uniprot\" \n",
    "# print(get_Uniprot) #(ID_Uniprot, Subcelular location, Function, Protein seq, length_aa) \n",
    "\n",
    "a=[\"N/A_Uniprot\"]\n",
    "\n",
    "try:\n",
    "    sec1 = 'INSERT INTO Uniprot (ID_Uniprot, Subcelular_Location, Function, Protein_sequence, length_aa, Link_Uniprot) VALUES (%s, %s, %s, %s, %s, %s)'\n",
    "    Cursor.execute(sec1, (a[0],a[0],a[0],a[0],a[0],a[0]))\n",
    "    for index, value in enumerate(get_Uniprot):\n",
    "        if str(value[0]) == 'N/A_Uniprot':\n",
    "            continue\n",
    "        else:\n",
    "            sql13= \"INSERT INTO Uniprot (ID_Uniprot, Subcelular_Location, Function, Protein_sequence, length_aa, Link_Uniprot) VALUES (%s, %s, %s, %s, %s, %s)\"\n",
    "            val13=(str(value[0]), str(value[1]), str(value[2]), str(value[3]), str(value[4]), str(value[5]))\n",
    "            Cursor.execute(sql13,val13)\n",
    "\n",
    "except mysql.connector.Error as e:\n",
    "    print(\"Erro na escrita na base de dados: {}\".format(e) )    \n",
    "\n",
    "#Povoação \"CDS\"\n",
    "try:\n",
    "    for item in join_CDS:\n",
    "        sql14= \"INSERT INTO CDS (ID_CDS, Translation, Location, ID_genebank, ID_Uniprot) VALUES (%s, %s, %s, %s, %s)\"\n",
    "        val14=(str(item[1]),str(item[4]),str(item[3]),str(item[0]),str(item[2]))\n",
    "        Cursor.execute(sql14,val14)\n",
    "except mysql.connector.Error as e:\n",
    "    print(\"Erro na escrita na base de dados: {}\".format(e) )    \n",
    "finally:\n",
    "    DataBase.close()\n",
    "\n",
    "print(\"Concluido\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a47a948f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rodri\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\rodri\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\rodri\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\rodri\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\rodri\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\rodri\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID_search     Search  Genes_number_input                 Day  \\\n",
      "0         22  diabetes                   15 2023-01-19 11:54:41   \n",
      "\n",
      "   Genes_number_NCBI  Protein_number  \n",
      "0                  8               4  \n",
      "  ID_genebank                                        Description  \\\n",
      "0    M90830.1  Xerocomus chrysenteron 18S ribosomal RNA gene,...   \n",
      "1    M94340.1  Xerocomus chrysenteron 18S ribosomal RNA gene,...   \n",
      "2    V00883.1  Rabbit (O. cuniculus) germ line gene coding fo...   \n",
      "3    V01310.1  Yeast (S. cerevisiae) gene HIS4 (histidine met...   \n",
      "4    X61243.1                           C.elegans repetitive DNA   \n",
      "5    X67017.1  S.cerevisiae cyt2 gene for cytochrome c heme l...   \n",
      "6    Z15032.1  S.cerevisiae gene for S.pombe cdc21+ homologue...   \n",
      "7    Z17674.1  ATTS0248 Gif-SeedA+B Arabidopsis thaliana cDNA...   \n",
      "\n",
      "                    Organism date_publish                 sequence  length  \\\n",
      "0  Xerocomellus chrysenteron  09-APR-2001  GCAAGTCTGG...TTGACGGAAG     604   \n",
      "1  Xerocomellus chrysenteron  09-APR-2001  AAAGATTAAG...AACCTGCGGA    1759   \n",
      "2      Oryctolagus cuniculus  14-NOV-2006  AAGCTTCTCT...TGTGGAATTC    1905   \n",
      "3   Saccharomyces cerevisiae  18-APR-2005  CTCGAGAAGA...TAGGAAAGAA    4751   \n",
      "4     Caenorhabditis elegans  30-SEP-2005  TTTTTTTACT...CTAACAATTT     578   \n",
      "5   Saccharomyces cerevisiae  13-JUN-2006  CCGGCCTTCT...TTTCCACCGG    1416   \n",
      "6   Saccharomyces cerevisiae  25-JUL-2016  TCTACTTCCA...CGTCTTGCAC     228   \n",
      "7       Arabidopsis thaliana  10-NOV-1992  GAGCAATAAT...ATCTTTTACC     720   \n",
      "\n",
      "   Adenina  Citosina  Timina  Guanina  \\\n",
      "0       25        18      26       28   \n",
      "1       25        20      26       27   \n",
      "2       28        19      27       24   \n",
      "3       32        19      26       21   \n",
      "4       32        22      31       14   \n",
      "5       30        23      29       17   \n",
      "6       26        16      34       22   \n",
      "7       24        22      30       21   \n",
      "\n",
      "                                            Link  ID_search  \n",
      "0  https://www.ncbi.nlm.nih.gov/nuccore/M90830.1         22  \n",
      "1  https://www.ncbi.nlm.nih.gov/nuccore/M94340.1         22  \n",
      "2  https://www.ncbi.nlm.nih.gov/nuccore/V00883.1         22  \n",
      "3  https://www.ncbi.nlm.nih.gov/nuccore/V01310.1         22  \n",
      "4  https://www.ncbi.nlm.nih.gov/nuccore/X61243.1         22  \n",
      "5  https://www.ncbi.nlm.nih.gov/nuccore/X67017.1         22  \n",
      "6  https://www.ncbi.nlm.nih.gov/nuccore/Z15032.1         22  \n",
      "7  https://www.ncbi.nlm.nih.gov/nuccore/Z17674.1         22  \n",
      "  ID_genebank  ID_AI_PubMed\n",
      "0    M90830.1           191\n",
      "1    M94340.1           187\n",
      "2    V00883.1           188\n",
      "3    V01310.1           193\n",
      "4    X61243.1           190\n",
      "5    X67017.1           189\n",
      "6    Z15032.1           192\n",
      "7    Z17674.1           187\n",
      "   ID_AI_PubMed                                              Title ID_PumMed  \\\n",
      "0           187                                          [['N/A']]       N/A   \n",
      "1           188  ['The nucleotide sequence of rabbit embryonic ...   6271761   \n",
      "2           189  ['Molecular cloning and characterization of th...   1499554   \n",
      "3           190  ['Molecular and genomic organization of cluste...   1619649   \n",
      "4           191  ['Rate and mode differences between nuclear an...   1382179   \n",
      "5           192  ['Fission yeast cdc21+ belongs to a family of ...   1454522   \n",
      "6           193  ['The nucleotide sequence of the HIS4 region o...   7049842   \n",
      "\n",
      "                               Doi_number  \n",
      "0                                     N/A  \n",
      "1                                     N/A  \n",
      "2     10.1111/j.1432-1033.1992.tb17146.x.  \n",
      "3           10.1016/0022-2836(92)90131-3.  \n",
      "4  10.1093/oxfordjournals.molbev.a040760.  \n",
      "5                 10.1093/nar/20.21.5571.  \n",
      "6           10.1016/0378-1119(82)90055-5.  \n",
      "    ID_AI_PubMed  ID_Authors\n",
      "0            187         561\n",
      "1            188         562\n",
      "2            189         563\n",
      "3            189         564\n",
      "4            189         565\n",
      "5            190         566\n",
      "6            190         567\n",
      "7            190         568\n",
      "8            190         569\n",
      "9            190         570\n",
      "10           191         571\n",
      "11           191         572\n",
      "12           192         573\n",
      "13           192         574\n",
      "14           192         575\n",
      "15           193         576\n",
      "16           193         577\n",
      "17           193         578\n",
      "    ID_Authors          Name\n",
      "0          561           N/A\n",
      "1          562   Hardison RC\n",
      "2          563     Zollner A\n",
      "3          564       Rodel G\n",
      "4          565        Haid A\n",
      "5          566    Naclerio G\n",
      "6          567    Cangiano G\n",
      "7          568     Coulson A\n",
      "8          569      Levitt A\n",
      "9          570      Ruvolo V\n",
      "10         571      Bruns TD\n",
      "11         572      Szaro TM\n",
      "12         573       Coxon A\n",
      "13         574   Maundrell K\n",
      "14         575    Kearsey SE\n",
      "15         576    Donahue TF\n",
      "16         577  Farabaugh PJ\n",
      "17         578       Fink GR\n",
      "   ID_AI_PubMed                                              Title ID_PumMed  \\\n",
      "0           187                                          [['N/A']]       N/A   \n",
      "1           188  ['The nucleotide sequence of rabbit embryonic ...   6271761   \n",
      "2           189  ['Molecular cloning and characterization of th...   1499554   \n",
      "3           190  ['Molecular and genomic organization of cluste...   1619649   \n",
      "4           191  ['Rate and mode differences between nuclear an...   1382179   \n",
      "5           192  ['Fission yeast cdc21+ belongs to a family of ...   1454522   \n",
      "6           193  ['The nucleotide sequence of the HIS4 region o...   7049842   \n",
      "\n",
      "                               Doi_number  \n",
      "0                                     N/A  \n",
      "1                                     N/A  \n",
      "2     10.1111/j.1432-1033.1992.tb17146.x.  \n",
      "3           10.1016/0022-2836(92)90131-3.  \n",
      "4  10.1093/oxfordjournals.molbev.a040760.  \n",
      "5                 10.1093/nar/20.21.5571.  \n",
      "6           10.1016/0378-1119(82)90055-5.  \n",
      "   ID_AI_PubMed  ID_affiliation\n",
      "0           187             141\n",
      "1           188             141\n",
      "2           193             141\n",
      "3           189             142\n",
      "4           190             143\n",
      "5           191             144\n",
      "6           192             145\n",
      "   ID_Affiliation                                               Info\n",
      "0             141                                                N/A\n",
      "1             142  Institut fur Genetik und Mikrobiologie, Univer...\n",
      "2             143  CNR International Institute of Genetics and Bi...\n",
      "3             144  Department of Plant Pathology, University of C...\n",
      "4             145   Department of Zoology, University of Oxford, UK.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rodri\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\rodri\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\rodri\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\rodri\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       ID_CDS                                        Translation  \\\n",
      "0  CAA24252.1  ['MVHFTAEEKAAITSTWKLVDVEDAGAEALGRLLVVYPWTQRFFD...   \n",
      "1  CAA24617.1  ['MVLPILPLIDDLASWNSKKEYVSLVGQVLLDGSSLSNEEILQFS...   \n",
      "2  CAA47407.1  ['MMSSDQQGKCPVDEETKKLWLREHGNEAHPGATAPGNQLECSAN...   \n",
      "3  CAA78750.1  ['STSKSQILQYVHKITPRGVYTSGKGSSAVGLTAYITRDVDTKQL...   \n",
      "4     N/A_CDS                                                N/A   \n",
      "5     N/A_CDS                                                N/A   \n",
      "6     N/A_CDS                                                N/A   \n",
      "7     N/A_CDS                                                N/A   \n",
      "\n",
      "                                          Location ID_genebank   ID_Uniprot  \n",
      "0  ['[223 : 316]', '[440 : 662]', '[1479 : 1608]']    V00883.1       P02099  \n",
      "1                                    [1331 : 3731]    V01310.1       P00815  \n",
      "2                                      [246 : 921]    X67017.1       Q00873  \n",
      "3                                      [<0 : >228]    Z15032.1       P30665  \n",
      "4                                              N/A    M90830.1  N/A_Uniprot  \n",
      "5                                              N/A    M94340.1  N/A_Uniprot  \n",
      "6                                              N/A    X61243.1  N/A_Uniprot  \n",
      "7                                              N/A    Z17674.1  N/A_Uniprot  \n",
      "    ID_Uniprot                                           Function  \\\n",
      "0  N/A_Uniprot                                        N/A_Uniprot   \n",
      "1       P00815                                                N/A   \n",
      "2       P02099  This protein functions as an embryonic globin,...   \n",
      "3       P30665                                                N/A   \n",
      "4       Q00873  Lyase that catalyzes the covalent linking of t...   \n",
      "\n",
      "                                 Subcelular_Location  \\\n",
      "0                                        N/A_Uniprot   \n",
      "1                                                N/A   \n",
      "2                                                N/A   \n",
      "3                             Nucleus {ECO:0000250}.   \n",
      "4  Mitochondrion inner membrane {ECO:0000269|PubM...   \n",
      "\n",
      "                                    Protein_sequence   length_aa  \\\n",
      "0                                        N/A_Uniprot  N/A_Unipro   \n",
      "1  MVLPILPLIDDLASWNSKKEYVSLVGQVLLDGSSLSNEEILQFSKE...         799   \n",
      "2  MVHFTAEEKAAITSTWKLVDVEDAGAEALGRLLVVYPWTQRFFDSF...         147   \n",
      "3  MSQQSSSPTKEDNNSSSPVVPNPDSVPPQLSSPALFYSSSSSQGDI...         933   \n",
      "4  MMSSDQQGKCPVDEETKKLWLREHGNEAHPGATAPGNQLECSANPQ...         224   \n",
      "\n",
      "                                    Link_Uniprot  \n",
      "0                                    N/A_Uniprot  \n",
      "1  https://www.uniprot.org/uniprotkb/P00815/entr  \n",
      "2  https://www.uniprot.org/uniprotkb/P02099/entr  \n",
      "3  https://www.uniprot.org/uniprotkb/P30665/entr  \n",
      "4  https://www.uniprot.org/uniprotkb/Q00873/entr  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rodri\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "DataBase = SQLC.connect(\n",
    "    host =\"geo.di.uminho.pt\",\n",
    "    user =\"bioinformatica\",\n",
    "    password =\"20221207\",\n",
    "    database =\"AP_db_KRG\"\n",
    ")\n",
    "tabela1 = pd.read_sql(\"Select * FROM History\", DataBase)\n",
    "print(tabela1)\n",
    "tabela2 = pd.read_sql(\"Select * FROM Gene\", DataBase)\n",
    "print(tabela2)\n",
    "tabela3 = pd.read_sql(\"Select * FROM gene_PubMed\", DataBase)\n",
    "print(tabela3)\n",
    "tabela4 = pd.read_sql(\"Select * FROM PubMed\", DataBase)\n",
    "print(tabela4)\n",
    "tabela5 = pd.read_sql(\"Select * FROM PubMed_Authors\", DataBase)\n",
    "print(tabela5)\n",
    "tabela6 = pd.read_sql(\"Select * FROM Authors\", DataBase)\n",
    "print(tabela6)\n",
    "tabela7 = pd.read_sql(\"Select * FROM PubMed\", DataBase)\n",
    "print(tabela7)\n",
    "tabela8 = pd.read_sql(\"Select * FROM PubMed_Affiliation\", DataBase)\n",
    "print(tabela8)\n",
    "tabela9 = pd.read_sql(\"Select * FROM Affiliation\", DataBase)\n",
    "print(tabela9)\n",
    "tabela10 = pd.read_sql(\"Select * FROM CDS\", DataBase)#print(tabela10)\n",
    "print(tabela10)\n",
    "tabela11 = pd.read_sql(\"Select * FROM Uniprot\", DataBase)\n",
    "print(tabela11)\n",
    "DataBase.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "05afcd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete de tudo \n",
    "\n",
    "DataBase = SQLC.connect(\n",
    "    host =\"geo.di.uminho.pt\",\n",
    "    user =\"bioinformatica\",\n",
    "    password =\"20221207\",\n",
    "    database =\"AP_db_KRG\"\n",
    ")\n",
    "DataBase.autocommit = True # allows the change be done\n",
    "\n",
    "Cursor = DataBase.cursor()\n",
    "try:\n",
    "        \n",
    "        a= \"delete from PubMed_Affiliation\"\n",
    "        Z= \"delete from PubMed_Authors\"\n",
    "        b= \"delete from Affiliation\"\n",
    "        c= \"delete from Authors\"\n",
    "        d= \"delete from gene_PubMed\"\n",
    "        e= \"delete from PubMed\"\n",
    "        f= \"delete from CDS\"\n",
    "        g= \"delete from Uniprot\"\n",
    "        h= \"delete from Gene\"\n",
    "        i= \"delete from History\"     \n",
    "        \n",
    "        Cursor.execute(a)\n",
    "        Cursor.execute(Z)\n",
    "        Cursor.execute(b)\n",
    "        Cursor.execute(c)\n",
    "        Cursor.execute(d)\n",
    "        Cursor.execute(e)\n",
    "        Cursor.execute(f)\n",
    "        Cursor.execute(g)\n",
    "        Cursor.execute(h)\n",
    "        Cursor.execute(i)\n",
    "        \n",
    "except mysql.connector.Error as e:\n",
    "    print(\"Erro na escrita na base de dados: {}\".format(e) )    \n",
    "finally:\n",
    "    DataBase.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329701bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
